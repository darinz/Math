{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Vectors and Vector Operations\n\n[![Chapter](https://img.shields.io/badge/Chapter-1-blue.svg)]()\n[![Topic](https://img.shields.io/badge/Topic-Vectors-green.svg)]()\n[![Difficulty](https://img.shields.io/badge/Difficulty-Beginner-brightgreen.svg)]()\n\n## Introduction\n\nVectors are fundamental objects in linear algebra that represent both magnitude and direction. In AI/ML and data science, vectors are used to represent data points, features, and parameters in mathematical models. Understanding vectors is crucial for grasping more advanced concepts like matrices, linear transformations, and machine learning algorithms.\n\n### Why Vectors Matter in AI/ML\n\n1. **Feature Representation**: Each data point in a dataset can be represented as a vector where each component corresponds to a feature\n2. **Model Parameters**: Neural network weights, regression coefficients, and other model parameters are stored as vectors\n3. **Embeddings**: Word embeddings, image embeddings, and other learned representations are vectors\n4. **Optimization**: Gradient descent and other optimization algorithms work with vectors of gradients\n\n## What is a Vector?\n\nA vector is an ordered list of numbers (scalars) that can represent:\n- **Points in space**: Each component represents a coordinate in n-dimensional space\n- **Directions and magnitudes**: Vectors can point in specific directions with specific lengths\n- **Features of data points**: Each component represents a different feature or attribute\n- **Parameters in machine learning models**: Weights, biases, and other learnable parameters\n\n### Geometric Interpretation\n\nIn 2D space, a vector $\\vec{v} = [x, y]$ represents:\n- A point $(x, y)$ in the plane\n- An arrow from the origin $(0, 0)$ to the point $(x, y)$\n- A displacement with magnitude $\\sqrt{x^2 + y^2}$ and direction $\\tan^{-1}(y/x)$\n\nIn 3D space, a vector $\\vec{v} = [x, y, z]$ represents:\n- A point $(x, y, z)$ in 3D space\n- An arrow from the origin $(0, 0, 0)$ to the point $(x, y, z)$\n- A displacement with magnitude $\\sqrt{x^2 + y^2 + z^2}$\n\n## Vector Representation\n\n### Mathematical Notation\n\nA vector $\\vec{v}$ in $\\mathbb{R}^n$ (n-dimensional real space) is written as:\n$$\\vec{v} = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\end{bmatrix}$$\n\nWhere:\n- $v_i$ is the $i$-th component of the vector\n- $n$ is the dimension of the vector space\n- $\\mathbb{R}^n$ denotes the set of all n-tuples of real numbers\n\n### Vector Types\n\n1. **Row Vector**: $\\vec{v} = [v_1, v_2, \\ldots, v_n]$\n2. **Column Vector**: $\\vec{v} = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\end{bmatrix}$\n\nIn linear algebra, we typically work with column vectors, but row vectors are useful for certain operations.\n\n### Python Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Creating vectors\nv1 = np.array([1, 2, 3])  # 3D vector\nv2 = np.array([4, 5, 6])\nv3 = np.array([1, 2])     # 2D vector\n\nprint(\"Vector v1:\", v1)\nprint(\"Vector v2:\", v2)\nprint(\"Vector v3:\", v3)\nprint(\"Shape of v1:\", v1.shape)\nprint(\"Dimension of v1:\", v1.ndim)\n\n# Creating vectors with different methods\nzeros_vector = np.zeros(5)  # Zero vector\nones_vector = np.ones(4)    # Vector of ones\nrandom_vector = np.random.randn(3)  # Random vector\nlinspace_vector = np.linspace(0, 10, 5)  # Equally spaced values\n\nprint(\"Zero vector:\", zeros_vector)\nprint(\"Ones vector:\", ones_vector)\nprint(\"Random vector:\", random_vector)\nprint(\"Linspace vector:\", linspace_vector)\n\n# Vector types and data types\nprint(\"Data type of v1:\", v1.dtype)\nprint(\"Is v1 a 1D array?\", v1.ndim == 1)\nprint(\"Length of v1:\", len(v1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vector Operations\n\n### 1. Vector Addition\n\n**Mathematical Definition:**\nVector addition is performed component-wise:\n$$\\vec{a} + \\vec{b} = \\begin{bmatrix} a_1 + b_1 \\\\ a_2 + b_2 \\\\ \\vdots \\\\ a_n + b_n \\end{bmatrix}$$\n\n**Geometric Interpretation:**\n- In 2D/3D: Vector addition follows the parallelogram law\n- The sum vector represents the diagonal of the parallelogram formed by the two vectors\n- This is equivalent to placing the tail of the second vector at the head of the first\n\n**Properties:**\n- **Commutative**: $\\vec{a} + \\vec{b} = \\vec{b} + \\vec{a}$\n- **Associative**: $(\\vec{a} + \\vec{b}) + \\vec{c} = \\vec{a} + (\\vec{b} + \\vec{c})$\n- **Identity**: $\\vec{a} + \\vec{0} = \\vec{a}$ (where $\\vec{0}$ is the zero vector)\n- **Inverse**: $\\vec{a} + (-\\vec{a}) = \\vec{0}$\n\n**Python Implementation:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vector addition\nresult = v1 + v2\nprint(\"v1 + v2 =\", result)\n\n# Element-wise addition\nresult_manual = np.array([v1[0] + v2[0], v1[1] + v2[1], v1[2] + v2[2]])\nprint(\"Manual addition:\", result_manual)\n\n# Broadcasting with scalars\nresult_broadcast = v1 + 5  # Adds 5 to each component\nprint(\"v1 + 5 =\", result_broadcast)\n\n# Adding multiple vectors\nv4 = np.array([7, 8, 9])\nsum_all = v1 + v2 + v4\nprint(\"v1 + v2 + v4 =\", sum_all)\n\n# Verification of properties\nprint(\"Commutative property (v1 + v2 == v2 + v1):\", np.array_equal(v1 + v2, v2 + v1))\nprint(\"Associative property check:\", np.array_equal((v1 + v2) + v4, v1 + (v2 + v4)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Scalar Multiplication\n\n**Mathematical Definition:**\nScalar multiplication multiplies each component by a scalar:\n$$c\\vec{v} = \\begin{bmatrix} cv_1 \\\\ cv_2 \\\\ \\vdots \\\\ cv_n \\end{bmatrix}$$\n\n**Geometric Interpretation:**\n- If $c > 0$: The vector is scaled by factor $c$ in the same direction\n- If $c < 0$: The vector is scaled by factor $|c|$ in the opposite direction\n- If $c = 0$: The result is the zero vector\n- If $|c| > 1$: The vector is stretched\n- If $|c| < 1$: The vector is compressed\n\n**Properties:**\n- **Distributive over vector addition**: $c(\\vec{a} + \\vec{b}) = c\\vec{a} + c\\vec{b}$\n- **Distributive over scalar addition**: $(c + d)\\vec{a} = c\\vec{a} + d\\vec{a}$\n- **Associative**: $(cd)\\vec{a} = c(d\\vec{a})$\n- **Identity**: $1\\vec{a} = \\vec{a}$\n\n**Python Implementation:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scalar multiplication\nscalar = 2.5\nresult = scalar * v1\nprint(f\"{scalar} * v1 =\", result)\n\n# Negative vector\nnegative_v1 = -v1\nprint(\"-v1 =\", negative_v1)\n\n# Multiple scalar operations\nresult_chain = 2 * 3 * v1\nprint(\"2 * 3 * v1 =\", result_chain)\n\n# Verification of properties\nprint(\"Distributive over vector addition:\", \n      np.array_equal(2 * (v1 + v2), 2 * v1 + 2 * v2))\nprint(\"Associative property:\", \n      np.array_equal((2 * 3) * v1, 2 * (3 * v1)))\n\n# Scaling effects\nscales = [0.5, 1, 2, -1]\nfor scale in scales:\n    scaled = scale * v1\n    print(f\"{scale} * v1 = {scaled}, magnitude = {np.linalg.norm(scaled):.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Vector Subtraction\n\n**Mathematical Definition:**\nVector subtraction is defined as addition with the negative:\n$$\\vec{a} - \\vec{b} = \\vec{a} + (-\\vec{b}) = \\begin{bmatrix} a_1 - b_1 \\\\ a_2 - b_2 \\\\ \\vdots \\\\ a_n - b_n \\end{bmatrix}$$\n\n**Geometric Interpretation:**\n- $\\vec{a} - \\vec{b}$ represents the vector from the tip of $\\vec{b}$ to the tip of $\\vec{a}$\n- This is useful for finding displacement vectors and differences between points\n\n**Python Implementation:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vector subtraction\nresult = v1 - v2\nprint(\"v1 - v2 =\", result)\n\n# Equivalent to addition with negative\nresult_equivalent = v1 + (-v2)\nprint(\"v1 + (-v2) =\", result_equivalent)\n\n# Subtraction properties\nprint(\"v1 - v1 =\", v1 - v1)  # Should be zero vector\nprint(\"v1 - v2 = -(v2 - v1):\", np.array_equal(v1 - v2, -(v2 - v1)))\n\n# Distance between points (represented as vectors)\ndistance = np.linalg.norm(v1 - v2)\nprint(\"Distance between v1 and v2:\", distance)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vector Properties\n\n### 1. Magnitude (Length)\n\n**Mathematical Definition:**\nThe magnitude (or length) of a vector is given by the Euclidean norm:\n$$|\\vec{v}| = \\sqrt{v_1^2 + v_2^2 + \\cdots + v_n^2}$$\n\n**Geometric Interpretation:**\n- In 2D: $|\\vec{v}| = \\sqrt{x^2 + y^2}$ (Pythagorean theorem)\n- In 3D: $|\\vec{v}| = \\sqrt{x^2 + y^2 + z^2}$\n- The magnitude represents the \"size\" or \"length\" of the vector\n\n**Properties:**\n- $|\\vec{v}| \\geq 0$ (non-negative)\n- $|\\vec{v}| = 0$ if and only if $\\vec{v} = \\vec{0}$\n- $|c\\vec{v}| = |c| \\cdot |\\vec{v}|$ (scalar multiplication)\n- Triangle inequality: $|\\vec{a} + \\vec{b}| \\leq |\\vec{a}| + |\\vec{b}|$\n\n**Python Implementation:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vector magnitude\nmagnitude_v1 = np.linalg.norm(v1)\nprint(\"Magnitude of v1:\", magnitude_v1)\n\n# Manual calculation\nmagnitude_manual = np.sqrt(np.sum(v1**2))\nprint(\"Manual magnitude calculation:\", magnitude_manual)\n\n# Different norm types\nl1_norm = np.linalg.norm(v1, ord=1)  # Manhattan norm\nl2_norm = np.linalg.norm(v1, ord=2)  # Euclidean norm (default)\nl_inf_norm = np.linalg.norm(v1, ord=np.inf)  # Maximum norm\n\nprint(f\"L1 norm: {l1_norm:.2f}\")\nprint(f\"L2 norm: {l2_norm:.2f}\")\nprint(f\"L∞ norm: {l_inf_norm:.2f}\")\n\n# Verification of properties\nprint(\"Non-negative:\", magnitude_v1 >= 0)\nprint(\"Scalar multiplication:\", np.linalg.norm(2 * v1) == 2 * magnitude_v1)\nprint(\"Triangle inequality:\", np.linalg.norm(v1 + v2) <= magnitude_v1 + np.linalg.norm(v2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Unit Vector\n\nA unit vector has magnitude 1 and points in the same direction as the original vector.\n\n**Mathematical Definition:**\n$$\\hat{v} = \\frac{\\vec{v}}{|\\vec{v}|}$$\n\n**Geometric Interpretation:**\n- Unit vectors are used to represent pure directions\n- Any vector can be written as $\\vec{v} = |\\vec{v}| \\cdot \\hat{v}$\n- Unit vectors are fundamental in coordinate systems and basis representations\n\n**Properties:**\n- $|\\hat{v}| = 1$\n- $\\hat{v}$ points in the same direction as $\\vec{v}$\n- If $\\vec{v} = \\vec{0}$, the unit vector is undefined\n\n**Python Implementation:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Unit vector\nunit_v1 = v1 / np.linalg.norm(v1)\nprint(\"Unit vector of v1:\", unit_v1)\nprint(\"Magnitude of unit vector:\", np.linalg.norm(unit_v1))\n\n# Verification\nprint(\"Is unit vector magnitude 1?\", np.isclose(np.linalg.norm(unit_v1), 1))\n\n# Reconstructing original vector\nreconstructed = np.linalg.norm(v1) * unit_v1\nprint(\"Reconstructed v1:\", reconstructed)\nprint(\"Reconstruction successful?\", np.array_equal(v1, reconstructed))\n\n# Standard unit vectors (basis vectors)\ne1 = np.array([1, 0, 0])  # i-hat\ne2 = np.array([0, 1, 0])  # j-hat\ne3 = np.array([0, 0, 1])  # k-hat\n\nprint(\"Standard unit vectors:\")\nprint(\"e1 (i-hat):\", e1)\nprint(\"e2 (j-hat):\", e2)\nprint(\"e3 (k-hat):\", e3)\nprint(\"Magnitudes:\", [np.linalg.norm(e) for e in [e1, e2, e3]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dot Product (Inner Product)\n\n### Mathematical Definition\nThe dot product of two vectors is a scalar defined as:\n$$\\vec{a} \\cdot \\vec{b} = a_1b_1 + a_2b_2 + \\cdots + a_nb_n = |\\vec{a}||\\vec{b}|\\cos\\theta$$\n\nWhere $\\theta$ is the angle between the vectors.\n\n### Geometric Interpretation\n- The dot product measures the projection of one vector onto another\n- $\\vec{a} \\cdot \\vec{b} = |\\vec{a}| \\cdot |\\vec{b}| \\cos\\theta$\n- If vectors are perpendicular: $\\vec{a} \\cdot \\vec{b} = 0$\n- If vectors are parallel: $\\vec{a} \\cdot \\vec{b} = \\pm|\\vec{a}||\\vec{b}|$\n\n### Properties\n- **Commutative**: $\\vec{a} \\cdot \\vec{b} = \\vec{b} \\cdot \\vec{a}$\n- **Distributive**: $\\vec{a} \\cdot (\\vec{b} + \\vec{c}) = \\vec{a} \\cdot \\vec{b} + \\vec{a} \\cdot \\vec{c}$\n- **Scalar multiplication**: $(c\\vec{a}) \\cdot \\vec{b} = c(\\vec{a} \\cdot \\vec{b})$\n- **Positive definite**: $\\vec{a} \\cdot \\vec{a} = |\\vec{a}|^2 \\geq 0$\n\n### Python Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dot product\ndot_product = np.dot(v1, v2)\nprint(\"Dot product v1 · v2 =\", dot_product)\n\n# Alternative notation\ndot_product_alt = v1 @ v2\nprint(\"Dot product using @ operator:\", dot_product_alt)\n\n# Manual calculation\ndot_manual = sum(v1[i] * v2[i] for i in range(len(v1)))\nprint(\"Manual dot product:\", dot_manual)\n\n# Angle between vectors\ncos_angle = dot_product / (np.linalg.norm(v1) * np.linalg.norm(v2))\nangle_rad = np.arccos(np.clip(cos_angle, -1, 1))\nangle_deg = np.degrees(angle_rad)\nprint(f\"Angle between v1 and v2: {angle_deg:.2f} degrees\")\n\n# Verification of properties\nprint(\"Commutative property:\", np.dot(v1, v2) == np.dot(v2, v1))\nprint(\"Self dot product equals magnitude squared:\", \n      np.isclose(np.dot(v1, v1), np.linalg.norm(v1)**2))\n\n# Projection calculation\nprojection_length = dot_product / np.linalg.norm(v2)\nprojection_vector = projection_length * (v2 / np.linalg.norm(v2))\nprint(\"Projection of v1 onto v2:\", projection_vector)\n\n# Orthogonality test\northogonal_threshold = 1e-10\nis_orthogonal = abs(np.dot(v1, v2)) < orthogonal_threshold\nprint(\"Are v1 and v2 orthogonal?\", is_orthogonal)\n\n# Dot product with unit vectors\nprint(\"v1 · e1 =\", np.dot(v1, e1))  # x-component\nprint(\"v1 · e2 =\", np.dot(v1, e2))  # y-component\nprint(\"v1 · e3 =\", np.dot(v1, e3))  # z-component\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cross Product (3D Vectors Only)\n\n### Mathematical Definition\nThe cross product of two 3D vectors is a vector perpendicular to both:\n$$\\vec{a} \\times \\vec{b} = \\begin{bmatrix} a_2b_3 - a_3b_2 \\\\ a_3b_1 - a_1b_3 \\\\ a_1b_2 - a_2b_1 \\end{bmatrix}$$\n\n### Geometric Interpretation\n- The cross product produces a vector perpendicular to both input vectors\n- The direction follows the right-hand rule\n- The magnitude is $|\\vec{a} \\times \\vec{b}| = |\\vec{a}||\\vec{b}|\\sin\\theta$\n- The cross product is used to find normal vectors, areas, and volumes\n\n### Properties\n- **Anti-commutative**: $\\vec{a} \\times \\vec{b} = -(\\vec{b} \\times \\vec{a})$\n- **Distributive**: $\\vec{a} \\times (\\vec{b} + \\vec{c}) = \\vec{a} \\times \\vec{b} + \\vec{a} \\times \\vec{c}$\n- **Scalar multiplication**: $(c\\vec{a}) \\times \\vec{b} = c(\\vec{a} \\times \\vec{b})$\n- **Perpendicular to both vectors**: $\\vec{a} \\cdot (\\vec{a} \\times \\vec{b}) = 0$ and $\\vec{b} \\cdot (\\vec{a} \\times \\vec{b}) = 0$\n\n### Python Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cross product (only for 3D vectors)\ncross_product = np.cross(v1, v2)\nprint(\"Cross product v1 × v2 =\", cross_product)\n\n# Verify perpendicularity\nperpendicular_to_v1 = np.dot(cross_product, v1)\nperpendicular_to_v2 = np.dot(cross_product, v2)\nprint(\"Cross product · v1 =\", perpendicular_to_v1)\nprint(\"Cross product · v2 =\", perpendicular_to_v2)\n\n# Magnitude of cross product\ncross_magnitude = np.linalg.norm(cross_product)\nexpected_magnitude = np.linalg.norm(v1) * np.linalg.norm(v2) * np.sin(angle_rad)\nprint(\"Cross product magnitude:\", cross_magnitude)\nprint(\"Expected magnitude:\", expected_magnitude)\n\n# Verification of properties\nprint(\"Anti-commutative property:\", np.array_equal(cross_product, -np.cross(v2, v1)))\n\n# Area of parallelogram\narea = np.linalg.norm(cross_product)\nprint(\"Area of parallelogram formed by v1 and v2:\", area)\n\n# Unit normal vector\nnormal_unit = cross_product / np.linalg.norm(cross_product)\nprint(\"Unit normal vector:\", normal_unit)\n\n# Triple scalar product (volume of parallelepiped)\ntriple_scalar = np.dot(v1, np.cross(v2, v4))\nprint(\"Triple scalar product (volume):\", triple_scalar)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vector Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2D Vector Visualization\ndef plot_2d_vectors():\n    fig, ax = plt.subplots(figsize=(10, 8))\n    \n    # Origin\n    origin = np.array([0, 0])\n    \n    # Plot vectors\n    ax.quiver(origin[0], origin[1], v3[0], v3[1], \n              angles='xy', scale_units='xy', scale=1, color='blue', label='v3')\n    \n    # Add another vector\n    v4 = np.array([3, 1])\n    ax.quiver(origin[0], origin[1], v4[0], v4[1], \n              angles='xy', scale_units='xy', scale=1, color='red', label='v4')\n    \n    # Vector addition\n    v_sum = v3 + v4\n    ax.quiver(origin[0], origin[1], v_sum[0], v_sum[1], \n              angles='xy', scale_units='xy', scale=1, color='green', label='v3 + v4')\n    \n    # Parallelogram construction\n    ax.quiver(v3[0], v3[1], v4[0], v4[1], \n              angles='xy', scale_units='xy', scale=1, color='red', alpha=0.5)\n    ax.quiver(v4[0], v4[1], v3[0], v3[1], \n              angles='xy', scale_units='xy', scale=1, color='blue', alpha=0.5)\n    \n    # Set limits and labels\n    ax.set_xlim(-1, 5)\n    ax.set_ylim(-1, 4)\n    ax.set_xlabel('X')\n    ax.set_ylabel('Y')\n    ax.set_title('2D Vector Visualization')\n    ax.legend()\n    ax.grid(True, alpha=0.3)\n    ax.set_aspect('equal')\n    \n    plt.show()\n\n# 3D Vector Visualization\ndef plot_3d_vectors():\n    fig = plt.figure(figsize=(12, 8))\n    ax = fig.add_subplot(111, projection='3d')\n    \n    # Origin\n    origin = np.array([0, 0, 0])\n    \n    # Plot vectors\n    ax.quiver(origin[0], origin[1], origin[2], \n              v1[0], v1[1], v1[2], color='blue', label='v1', arrow_length_ratio=0.1)\n    ax.quiver(origin[0], origin[1], origin[2], \n              v2[0], v2[1], v2[2], color='red', label='v2', arrow_length_ratio=0.1)\n    \n    # Cross product\n    ax.quiver(origin[0], origin[1], origin[2], \n              cross_product[0], cross_product[1], cross_product[2], \n              color='green', label='v1 × v2', arrow_length_ratio=0.1)\n    \n    # Set limits and labels\n    ax.set_xlim(-1, 7)\n    ax.set_ylim(-1, 7)\n    ax.set_zlim(-1, 7)\n    ax.set_xlabel('X')\n    ax.set_ylabel('Y')\n    ax.set_zlabel('Z')\n    ax.set_title('3D Vector Visualization')\n    ax.legend()\n    \n    plt.show()\n\n# Run visualizations\nplot_2d_vectors()\nplot_3d_vectors()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Applications in AI/ML\n\n### 1. Feature Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Feature vector for a house\nhouse_features = np.array([\n    2000,    # square footage\n    3,       # bedrooms\n    2,       # bathrooms\n    2010,    # year built\n    250000   # price\n])\n\n# Normalize features for machine learning\nnormalized_features = (house_features - np.mean(house_features)) / np.std(house_features)\nprint(\"Normalized house features:\", normalized_features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Similarity Measures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cosine similarity between two documents (represented as word frequency vectors)\ndoc1 = np.array([1, 0, 2, 1, 0])  # word frequencies\ndoc2 = np.array([0, 1, 1, 0, 2])\n\ncosine_similarity = np.dot(doc1, doc2) / (np.linalg.norm(doc1) * np.linalg.norm(doc2))\nprint(\"Cosine similarity between documents:\", cosine_similarity)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Gradient Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Gradient of a simple function f(x,y) = x^2 + y^2\ndef gradient_2d(x, y):\n    return np.array([2*x, 2*y])\n\n# Gradient at point (1, 2)\ngrad = gradient_2d(1, 2)\nprint(\"Gradient at (1, 2):\", grad)\nprint(\"Gradient magnitude:\", np.linalg.norm(grad))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercises\n\n### Exercise 1: Vector Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Given vectors a = [1, 2, 3], b = [4, 5, 6], c = [7, 8, 9]\na = np.array([1, 2, 3])\nb = np.array([4, 5, 6])\nc = np.array([7, 8, 9])\n\n# Calculate: 2a + 3b - c\nresult = 2*a + 3*b - c\nprint(\"2a + 3b - c =\", result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 2: Vector Properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify the Cauchy-Schwarz inequality: |a·b| ≤ |a|·|b|\na = np.array([1, 2, 3])\nb = np.array([4, 5, 6])\n\ndot_product = np.dot(a, b)\nmagnitude_product = np.linalg.norm(a) * np.linalg.norm(b)\n\nprint(\"|a·b| =\", abs(dot_product))\nprint(\"|a|·|b| =\", magnitude_product)\nprint(\"Cauchy-Schwarz inequality holds:\", abs(dot_product) <= magnitude_product)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 3: Vector Decomposition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Decompose vector v into components parallel and perpendicular to u\nv = np.array([3, 4, 5])\nu = np.array([1, 0, 0])\n\n# Parallel component\nu_unit = u / np.linalg.norm(u)\nv_parallel = np.dot(v, u_unit) * u_unit\n\n# Perpendicular component\nv_perpendicular = v - v_parallel\n\nprint(\"Original vector v:\", v)\nprint(\"Parallel component:\", v_parallel)\nprint(\"Perpendicular component:\", v_perpendicular)\nprint(\"Sum of components:\", v_parallel + v_perpendicular)\nprint(\"Verification (should be zero):\", np.dot(v_parallel, v_perpendicular))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n\nIn this chapter, we've covered:\n\n1. **Vector Fundamentals**: Definition, representation, and geometric interpretation\n2. **Basic Operations**: Addition, scalar multiplication, and subtraction with detailed properties\n3. **Vector Properties**: Magnitude, unit vectors, and their geometric meaning\n4. **Dot Product**: Definition, properties, and applications in similarity and projection\n5. **Cross Product**: 3D vector operation for finding perpendicular vectors and areas\n6. **Visualization**: 2D and 3D plotting of vectors and their operations\n7. **AI/ML Applications**: Feature vectors, similarity measures, and gradients\n\n### Key Takeaways:\n- Vectors are fundamental for representing data and mathematical objects\n- Vector operations have both algebraic and geometric interpretations\n- The dot product measures similarity and projection\n- The cross product (in 3D) produces perpendicular vectors\n- Understanding vectors is essential for linear algebra and machine learning\n\n### Next Steps:\nIn the next chapter, we'll explore matrices, which are collections of vectors that enable more complex linear transformations and operations."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}