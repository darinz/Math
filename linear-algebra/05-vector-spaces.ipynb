{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Vector Spaces and Subspaces\n\n[![Chapter](https://img.shields.io/badge/Chapter-5-blue.svg)]()\n[![Topic](https://img.shields.io/badge/Topic-Vector_Spaces-green.svg)]()\n[![Difficulty](https://img.shields.io/badge/Difficulty-Intermediate-orange.svg)]()\n\n## Introduction\n\nVector spaces provide the mathematical foundation for linear algebra. They are sets of vectors that satisfy certain axioms and are fundamental for understanding linear transformations, subspaces, and the structure of linear systems. The concept of a vector space generalizes familiar spaces like $\\mathbb{R}^n$ and allows us to work with functions, polynomials, matrices, and more in a unified way.\n\n### Why Vector Spaces Matter in AI/ML\n\n1. **Feature Spaces**: Data points in ML are vectors in high-dimensional spaces\n2. **Parameter Spaces**: Model parameters (weights) form vector spaces\n3. **Function Spaces**: Solutions to differential equations, regression functions, and neural network outputs live in function spaces\n4. **Subspaces**: Principal components, null spaces, and column spaces are all subspaces\n5. **Basis and Dimension**: Feature selection, dimensionality reduction, and embeddings rely on these concepts\n\n## What is a Vector Space?\n\nA vector space $V$ over a field $F$ (usually $\\mathbb{R}$ or $\\mathbb{C}$) is a set of objects (called vectors) with two operations:\n1. **Vector addition**: $u + v \\in V$ for all $u, v \\in V$\n2. **Scalar multiplication**: $cu \\in V$ for all $c \\in F, u \\in V$\n\n### Axioms of a Vector Space\nA set $V$ is a vector space if, for all $u, v, w \\in V$ and $c, d \\in F$:\n- **Commutativity**: $u + v = v + u$\n- **Associativity (addition)**: $(u + v) + w = u + (v + w)$\n- **Additive identity**: There exists $0 \\in V$ such that $v + 0 = v$\n- **Additive inverse**: For each $v \\in V$, there exists $-v$ such that $v + (-v) = 0$\n- **Distributivity (vector)**: $c(u + v) = cu + cv$\n- **Distributivity (scalar)**: $(c + d)u = cu + du$\n- **Associativity (scalar)**: $c(du) = (cd)u$\n- **Scalar identity**: $1u = u$\n\n#### Examples and Counterexamples\n- $\\mathbb{R}^n$ is a vector space (all axioms hold)\n- The set of all $2 \\times 2$ matrices is a vector space\n- The set of polynomials of degree $\\leq n$ is a vector space\n- The set of vectors in $\\mathbb{R}^2$ with positive entries is **not** a vector space (not closed under scalar multiplication by negative numbers)\n- The set of solutions to a homogeneous linear system is a vector space\n\n## Common Vector Spaces\n\n### $\\mathbb{R}^n$ (Real Vector Space)\n$\\mathbb{R}^n$ is the set of all $n$-tuples of real numbers. It is the prototypical example of a vector space and forms the basis for most data representations in ML."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n\n# ℝ² - 2D real vectors\nv1 = np.array([1, 2])\nv2 = np.array([3, 4])\n\n# Vector addition\nv_sum = v1 + v2\nprint(f\"v1 + v2 = {v_sum}\")\n\n# Scalar multiplication\nscaled_v = 2 * v1\nprint(f\"2 * v1 = {scaled_v}\")\n\n# Zero vector\nzero_vector = np.zeros(2)\nprint(f\"Zero vector: {zero_vector}\")\n\n# Verify axioms\nprint(f\"v1 + v2 = v2 + v1: {np.array_equal(v1 + v2, v2 + v1)}\")  # Commutativity\nv3 = np.array([5, 6])\nprint(f\"(v1 + v2) + v3 = v1 + (v2 + v3): {np.array_equal((v1 + v2) + v3, v1 + (v2 + v3))}\")  # Associativity\nprint(f\"v1 + 0 = v1: {np.array_equal(v1 + zero_vector, v1)}\")  # Additive identity\nprint(f\"v1 + (-v1) = 0: {np.array_equal(v1 + (-v1), zero_vector)}\")  # Additive inverse\nprint(f\"2*(v1 + v2) = 2*v1 + 2*v2: {np.array_equal(2*(v1 + v2), 2*v1 + 2*v2)}\")  # Distributivity\nprint(f\"(2+3)*v1 = 2*v1 + 3*v1: {np.array_equal((2+3)*v1, 2*v1 + 3*v1)}\")  # Scalar distributivity\nprint(f\"2*(3*v1) = (2*3)*v1: {np.array_equal(2*(3*v1), (2*3)*v1)}\")  # Scalar associativity\nprint(f\"1*v1 = v1: {np.array_equal(1*v1, v1)}\")  # Scalar identity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Counterexample: Not a Vector Space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set of vectors in ℝ² with only positive entries\nv_pos1 = np.array([1, 2])\nv_pos2 = np.array([3, 4])\n\n# Scalar multiplication by negative number\nneg_scaled = -1 * v_pos1\nprint(f\"-1 * v_pos1 = {neg_scaled}\")  # Not in the set of positive vectors\n# This set is not closed under scalar multiplication, so it is not a vector space\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function Spaces\nFunction spaces are vector spaces where the elements are functions. For example, the set of all polynomials of degree $\\leq 2$ forms a vector space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Space of polynomials of degree ≤ 2\ndef polynomial_space_example():\n    # Basis: {1, x, x²}\n    p1 = lambda x: 1 + 2*x + 3*x**2  # 1 + 2x + 3x²\n    p2 = lambda x: 2 - x + x**2      # 2 - x + x²\n    \n    # Vector addition (function addition)\n    p_sum = lambda x: p1(x) + p2(x)\n    \n    # Scalar multiplication\n    p_scaled = lambda x: 2 * p1(x)\n    \n    # Test at x = 1\n    x_test = 1\n    print(f\"p1({x_test}) = {p1(x_test)}\")\n    print(f\"p2({x_test}) = {p2(x_test)}\")\n    print(f\"(p1 + p2)({x_test}) = {p_sum(x_test)}\")\n    print(f\"(2*p1)({x_test}) = {p_scaled(x_test)}\")\n    \n    # Check closure: sum and scalar multiple are still polynomials of degree ≤ 2\n    print(f\"(p1 + p2) is degree ≤ 2: True\")\n    print(f\"(2*p1) is degree ≤ 2: True\")\n\npolynomial_space_example()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Subspaces\n\nA subspace $W$ of a vector space $V$ is a subset that is itself a vector space under the same operations. Subspaces are important because they represent solution sets to homogeneous equations, null spaces, column spaces, and more.\n\n### Subspace Criteria\nFor $W$ to be a subspace of $V$:\n1. **Contains zero vector**: $0 \\in W$\n2. **Closure under addition**: $u, v \\in W \\implies u + v \\in W$\n3. **Closure under scalar multiplication**: $u \\in W, c \\in F \\implies cu \\in W$\n\nIf all three hold, $W$ automatically satisfies all vector space axioms (since it inherits them from $V$).\n\n#### Examples\n- The set of all vectors on a line through the origin in $\\mathbb{R}^2$ is a subspace\n- The set of all $n \\times n$ symmetric matrices is a subspace of all $n \\times n$ matrices\n- The set of all solutions to $Ax = 0$ (the null space) is a subspace\n\n#### Counterexamples\n- The set of vectors in $\\mathbb{R}^2$ with $x \\geq 0$ is **not** a subspace (not closed under scalar multiplication by negative numbers)\n- The set of vectors in $\\mathbb{R}^2$ with $x + y = 1$ is **not** a subspace (does not contain the zero vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def is_subspace(vectors, test_vectors=None):\n    \"\"\"Check if a set of vectors forms a subspace (simple check)\"\"\"\n    if test_vectors is None:\n        test_vectors = [\n            np.array([1, 0]),\n            np.array([0, 1]),\n            np.array([1, 1]),\n            np.array([0, 0])\n        ]\n    \n    # Check if zero vector is in the set\n    zero_in_set = any(np.allclose(v, np.zeros_like(v)) for v in vectors)\n    \n    # Check closure under addition and scalar multiplication for a few pairs\n    closed_add = all(np.any([np.allclose(u + v, w) for w in vectors]) for u in vectors for v in vectors)\n    closed_scalar = all(np.any([np.allclose(c * v, w) for w in vectors]) for v in vectors for c in [-1, 2])\n    \n    return zero_in_set and closed_add and closed_scalar\n\n# Example: Line through origin in ℝ² (subspace)\nline_vectors = [np.array([1, 2]), np.array([2, 4]), np.array([0, 0])]\nprint(f\"Line through origin is subspace: {is_subspace(line_vectors)}\")\n\n# Example: Plane not through origin (not a subspace)\nplane_vectors = [np.array([1, 0, 1]), np.array([0, 1, 1]), np.array([1, 1, 2])]\nprint(f\"Plane not through origin is subspace: {is_subspace(plane_vectors)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Span\n\nThe span of a set of vectors is the set of all linear combinations of those vectors. The span is always a subspace.\n\n**Mathematical Definition:**\n$$\\text{span}\\{v_1, \\ldots, v_k\\} = \\{c_1 v_1 + \\cdots + c_k v_k : c_i \\in F\\}$$\n\n**Geometric Interpretation:**\n- The span of one nonzero vector in $\\mathbb{R}^2$ is a line through the origin\n- The span of two linearly independent vectors in $\\mathbb{R}^2$ is the whole plane\n- The span of $k$ vectors in $\\mathbb{R}^n$ is a $\\leq k$-dimensional subspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def span_vectors(vectors, coefficients):\n    \"\"\"Compute linear combination of vectors\"\"\"\n    result = np.zeros_like(vectors[0])\n    for v, c in zip(vectors, coefficients):\n        result += c * v\n    return result\n\n# Example: Span of two vectors in ℝ²\nv1 = np.array([1, 0])\nv2 = np.array([0, 1])\n\n# Different linear combinations\ncombinations = [\n    [1, 0],   # 1*v1 + 0*v2 = [1, 0]\n    [0, 1],   # 0*v1 + 1*v2 = [0, 1]\n    [2, 3],   # 2*v1 + 3*v2 = [2, 3]\n    [-1, 2]   # -1*v1 + 2*v2 = [-1, 2]\n]\n\nprint(\"Linear combinations:\")\nfor coeffs in combinations:\n    result = span_vectors([v1, v2], coeffs)\n    print(f\"{coeffs[0]}*v1 + {coeffs[1]}*v2 = {result}\")\n\n# The span of {v1, v2} is all of ℝ²\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linear Independence\n\nA set of vectors is linearly independent if no vector can be written as a linear combination of the others. Otherwise, they are linearly dependent.\n\n**Mathematical Definition:**\nVectors $v_1, \\ldots, v_k$ are linearly independent if the only solution to $c_1 v_1 + \\cdots + c_k v_k = 0$ is $c_1 = \\cdots = c_k = 0$.\n\n**Geometric Interpretation:**\n- In $\\mathbb{R}^2$, two vectors are independent if they are not collinear\n- In $\\mathbb{R}^3$, three vectors are independent if they do not all lie in the same plane\n\n**Why It Matters:**\n- The maximum number of linearly independent vectors in a space is its dimension\n- Basis vectors must be linearly independent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def is_linearly_independent(vectors, tol=1e-10):\n    \"\"\"Check if vectors are linearly independent\"\"\"\n    # Convert to matrix\n    matrix = np.column_stack(vectors)\n    \n    # Check rank\n    rank = np.linalg.matrix_rank(matrix)\n    \n    return rank == len(vectors)\n\n# Test linear independence\nindependent_vectors = [\n    np.array([1, 0]),\n    np.array([0, 1])\n]\nprint(f\"Independent vectors: {is_linearly_independent(independent_vectors)}\")\n\ndependent_vectors = [\n    np.array([1, 0]),\n    np.array([0, 1]),\n    np.array([1, 1])  # This is a linear combination of the first two\n]\nprint(f\"Dependent vectors: {is_linearly_independent(dependent_vectors)}\")\n\n# Example: Check independence in higher dimensions\nv3 = np.array([1, 2, 3])\nv4 = np.array([4, 5, 6])\nv5 = np.array([7, 8, 9])\nprint(f\"Are [v3, v4, v5] independent? {is_linearly_independent([v3, v4, v5])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basis and Dimension\n\nA **basis** for a vector space is a linearly independent set that spans the space. Every vector in the space can be written uniquely as a linear combination of basis vectors.\n\n**Mathematical Definition:**\nA set $\\{v_1, \\ldots, v_k\\}$ is a basis for $V$ if:\n- The vectors are linearly independent\n- $\\text{span}\\{v_1, \\ldots, v_k\\} = V$\n\n**Dimension:**\nThe number of vectors in any basis for $V$ is called the **dimension** of $V$, denoted $\\dim(V)$.\n\n**Geometric Interpretation:**\n- In $\\mathbb{R}^2$, any two non-collinear vectors form a basis\n- In $\\mathbb{R}^3$, any three non-coplanar vectors form a basis\n- The standard basis for $\\mathbb{R}^n$ is $\\{e_1, \\ldots, e_n\\}$ where $e_i$ has a 1 in the $i$-th position and 0 elsewhere\n\n**Why It Matters:**\n- The basis provides a coordinate system for the space\n- Dimensionality reduction (PCA) finds a new basis for the data\n- The number of features in ML is the dimension of the feature space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_basis(vectors):\n    \"\"\"Find a basis for the span of vectors\"\"\"\n    matrix = np.column_stack(vectors)\n    \n    # Use QR decomposition to find basis\n    Q, R, P = np.linalg.qr(matrix, mode='full', pivoting=True)\n    \n    # Find rank\n    rank = np.linalg.matrix_rank(matrix)\n    \n    # Return first 'rank' vectors as basis\n    basis = [vectors[P[i]] for i in range(rank)]\n    \n    return basis\n\n# Example: Find basis for ℝ³\nvectors_3d = [\n    np.array([1, 0, 0]),\n    np.array([0, 1, 0]),\n    np.array([0, 0, 1]),\n    np.array([1, 1, 1])  # Redundant vector\n]\n\nbasis = find_basis(vectors_3d)\nprint(\"Basis vectors:\")\nfor i, v in enumerate(basis):\n    print(f\"v{i+1} = {v}\")\n\nprint(f\"Dimension: {len(basis)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Null Space and Column Space\n\n### Null Space (Kernel)\nThe null space (or kernel) of a matrix $A$ is the set of vectors $x$ such that $Ax = 0$. It is a subspace of $\\mathbb{R}^n$ (where $n$ is the number of columns of $A$).\n\n**Why It Matters:**\n- The null space describes all solutions to the homogeneous system $Ax = 0$\n- In ML, the null space can indicate redundant features or dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def null_space(A, tol=1e-10):\n    \"\"\"Find null space of matrix A\"\"\"\n    U, S, Vt = np.linalg.svd(A)\n    \n    # Find singular values close to zero\n    null_indices = np.where(S < tol)[0]\n    \n    if len(null_indices) == 0:\n        return np.array([]).reshape(A.shape[1], 0)\n    \n    # Null space basis\n    null_basis = Vt[null_indices, :].T\n    \n    return null_basis\n\n# Example\nA = np.array([[1, 2, 3], [4, 5, 6]])\nprint(\"Matrix A:\")\nprint(A)\n\nnull_basis = null_space(A)\nprint(f\"\\nNull space dimension: {null_basis.shape[1]}\")\nif null_basis.size > 0:\n    print(\"Null space basis:\")\n    print(null_basis)\n    \n    # Verify: A * null_basis ≈ 0\n    verification = A @ null_basis\n    print(f\"\\nVerification (should be close to zero):\")\n    print(verification)\nelse:\n    print(\"Null space is trivial (only the zero vector)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Column Space (Range)\nThe column space (or range) of a matrix $A$ is the span of its columns. It is a subspace of $\\mathbb{R}^m$ (where $m$ is the number of rows of $A$).\n\n**Why It Matters:**\n- The column space represents all possible outputs $Ax$\n- The rank of $A$ is the dimension of the column space\n- In ML, the column space relates to the set of all possible predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def column_space(A):\n    \"\"\"Find column space of matrix A\"\"\"\n    Q, R, P = np.linalg.qr(A, mode='full', pivoting=True)\n    \n    # Find rank\n    rank = np.linalg.matrix_rank(A)\n    \n    # Return first 'rank' columns of Q as basis\n    col_basis = Q[:, :rank]\n    \n    return col_basis\n\n# Example\ncol_basis = column_space(A)\nprint(f\"Column space dimension: {col_basis.shape[1]}\")\nprint(\"Column space basis:\")\nprint(col_basis)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rank-Nullity Theorem\n\nFor any matrix $A$ with $n$ columns:\n$$\\text{rank}(A) + \\text{nullity}(A) = n$$\n\n- **Rank**: Dimension of the column space\n- **Nullity**: Dimension of the null space\n\n**Why It Matters:**\n- The theorem relates the number of independent columns to the number of free variables in $Ax = 0$\n- In ML, it helps diagnose redundancy and feature selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rank_nullity_theorem(A):\n    \"\"\"Verify rank-nullity theorem\"\"\"\n    rank = np.linalg.matrix_rank(A)\n    nullity = null_space(A).shape[1]\n    n = A.shape[1]\n    \n    print(f\"Rank: {rank}\")\n    print(f\"Nullity: {nullity}\")\n    print(f\"n: {n}\")\n    print(f\"Rank + Nullity = n: {rank + nullity == n}\")\n    \n    return rank, nullity\n\n# Test with different matrices\nA1 = np.array([[1, 2], [3, 4]])  # Full rank\nA2 = np.array([[1, 2], [2, 4]])  # Rank deficient\n\nprint(\"Matrix A1:\")\nrank_nullity_theorem(A1)\n\nprint(\"\\nMatrix A2:\")\nrank_nullity_theorem(A2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Applications in Machine Learning\n\n### Feature Space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Feature vectors in machine learning\nfeature_vectors = [\n    np.array([1, 2, 3]),  # Sample 1: [feature1, feature2, feature3]\n    np.array([4, 5, 6]),  # Sample 2\n    np.array([7, 8, 9]),  # Sample 3\n    np.array([2, 4, 6])   # Sample 4\n]\n\n# Check if features are linearly independent\nfeature_matrix = np.column_stack(feature_vectors)\nrank = np.linalg.matrix_rank(feature_matrix)\nprint(f\"Feature matrix rank: {rank}\")\nprint(f\"Number of features: {feature_matrix.shape[0]}\")\nprint(f\"Are features linearly independent? {rank == feature_matrix.shape[0]}\")\n\n# Find feature subspace\nfeature_basis = column_space(feature_matrix.T)\nprint(f\"Feature subspace dimension: {feature_basis.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Kernel Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rbf_kernel(x1, x2, gamma=1.0):\n    \"\"\"Radial Basis Function kernel\"\"\"\n    return np.exp(-gamma * np.linalg.norm(x1 - x2)**2)\n\n# Example: Kernel feature space\nX = np.array([[1, 2], [3, 4], [5, 6]])\nn_samples = X.shape[0]\n\n# Compute kernel matrix\nK = np.zeros((n_samples, n_samples))\nfor i in range(n_samples):\n    for j in range(n_samples):\n        K[i, j] = rbf_kernel(X[i], X[j])\n\nprint(\"Kernel matrix:\")\nprint(K)\n\n# Check if kernel matrix is positive definite\neigenvalues = np.linalg.eigvals(K)\nprint(f\"Kernel matrix eigenvalues: {eigenvalues}\")\nprint(f\"Is positive definite? {np.all(eigenvalues > 0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercises\n\n### Exercise 1: Subspace Verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if given sets are subspaces\nset1 = [np.array([1, 0]), np.array([0, 1]), np.array([0, 0])]  # ℝ²\nset2 = [np.array([1, 1]), np.array([2, 2]), np.array([0, 0])]  # Line through origin\n\n# Your code here:\n# 1. Check if each set is a subspace\n# 2. Find the dimension of each subspace\n# 3. Find a basis for each subspace\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 2: Linear Independence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test linear independence of vectors\nvectors = [\n    np.array([1, 2, 3]),\n    np.array([4, 5, 6]),\n    np.array([7, 8, 9]),\n    np.array([2, 4, 6])\n]\n\n# Your code here:\n# 1. Check if vectors are linearly independent\n# 2. Find a basis for their span\n# 3. Find the dimension of the span\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 3: Matrix Spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze matrix spaces\nA = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\n# Your code here:\n# 1. Find null space of A\n# 2. Find column space of A\n# 3. Verify rank-nullity theorem\n# 4. Find row space of A\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solutions\n\n### Solution 1: Subspace Verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Check if each set is a subspace\ndef check_subspace(vectors):\n    # Check if zero vector is present\n    has_zero = any(np.allclose(v, np.zeros_like(v)) for v in vectors)\n    \n    # Check closure under addition (simplified)\n    matrix = np.column_stack(vectors)\n    rank = np.linalg.matrix_rank(matrix)\n    \n    return has_zero and rank <= len(vectors)\n\nprint(f\"Set 1 is subspace: {check_subspace(set1)}\")\nprint(f\"Set 2 is subspace: {check_subspace(set2)}\")\n\n# 2. Find dimension\ndef subspace_dimension(vectors):\n    matrix = np.column_stack(vectors)\n    return np.linalg.matrix_rank(matrix)\n\nprint(f\"Set 1 dimension: {subspace_dimension(set1)}\")\nprint(f\"Set 2 dimension: {subspace_dimension(set2)}\")\n\n# 3. Find basis\nbasis1 = find_basis(set1)\nbasis2 = find_basis(set2)\n\nprint(\"Basis for set 1:\")\nfor v in basis1:\n    print(v)\nprint(\"Basis for set 2:\")\nfor v in basis2:\n    print(v)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Solution 2: Linear Independence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Check linear independence\nis_independent = is_linearly_independent(vectors)\nprint(f\"Vectors are linearly independent: {is_independent}\")\n\n# 2. Find basis\nbasis = find_basis(vectors)\nprint(f\"Basis vectors:\")\nfor i, v in enumerate(basis):\n    print(f\"v{i+1} = {v}\")\n\n# 3. Find dimension\ndimension = len(basis)\nprint(f\"Dimension of span: {dimension}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Solution 3: Matrix Spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Null space\nnull_basis = null_space(A)\nprint(f\"Null space dimension: {null_basis.shape[1]}\")\nif null_basis.size > 0:\n    print(\"Null space basis:\")\n    print(null_basis)\n\n# 2. Column space\ncol_basis = column_space(A)\nprint(f\"\\nColumn space dimension: {col_basis.shape[1]}\")\nprint(\"Column space basis:\")\nprint(col_basis)\n\n# 3. Verify rank-nullity theorem\nrank, nullity = rank_nullity_theorem(A)\n\n# 4. Row space (same as column space of A^T)\nrow_basis = column_space(A.T)\nprint(f\"\\nRow space dimension: {row_basis.shape[1]}\")\nprint(\"Row space basis:\")\nprint(row_basis)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n\nIn this chapter, we covered:\n- Definition and axioms of vector spaces\n- Subspaces and their properties\n- Span and linear independence\n- Basis and dimension\n- Null space and column space\n- Rank-nullity theorem\n- Applications in machine learning\n\nVector spaces provide the theoretical foundation for understanding linear algebra concepts and their applications.\n\n## Next Steps\n\nIn the next chapter, we'll explore linear independence and basis in more detail, focusing on coordinate systems and change of basis."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}