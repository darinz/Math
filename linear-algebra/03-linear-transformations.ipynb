{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Linear Transformations\n\n[![Chapter](https://img.shields.io/badge/Chapter-3-blue.svg)]()\n[![Topic](https://img.shields.io/badge/Topic-Linear_Transformations-green.svg)]()\n[![Difficulty](https://img.shields.io/badge/Difficulty-Intermediate-orange.svg)]()\n\n## Introduction\n\nLinear transformations are functions that preserve vector addition and scalar multiplication. They are fundamental in understanding how matrices transform vectors and spaces, which is crucial for machine learning algorithms. Linear transformations form the mathematical foundation for neural networks, dimensionality reduction, and many other AI/ML techniques.\n\n### Why Linear Transformations Matter in AI/ML\n\n1. **Neural Networks**: Each layer applies a linear transformation followed by a nonlinear activation\n2. **Dimensionality Reduction**: PCA, SVD, and other techniques use linear transformations\n3. **Feature Engineering**: Linear combinations of features are linear transformations\n4. **Optimization**: Gradient descent and other algorithms work with linear approximations\n5. **Computer Vision**: Image transformations, rotations, scaling are linear operations\n6. **Signal Processing**: Filters and transforms are often linear\n\n## What is a Linear Transformation?\n\nA function $T: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m$ is linear if it satisfies two fundamental properties:\n\n1. **Additivity**: $T(\\vec{u} + \\vec{v}) = T(\\vec{u}) + T(\\vec{v})$ for all vectors $\\vec{u}, \\vec{v} \\in \\mathbb{R}^n$\n2. **Homogeneity**: $T(c\\vec{u}) = cT(\\vec{u})$ for all scalars $c$ and vectors $\\vec{u} \\in \\mathbb{R}^n$\n\n### Mathematical Foundation\n\nThese properties can be combined into a single condition:\n$$T(a\\vec{u} + b\\vec{v}) = aT(\\vec{u}) + bT(\\vec{v})$$\n\nThis means linear transformations preserve linear combinations, which is why they're called \"linear.\"\n\n### Matrix Representation Theorem\n\n**Fundamental Theorem**: Every linear transformation $T: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m$ can be represented by a unique $m \\times n$ matrix $A$ such that:\n$$T(\\vec{x}) = A\\vec{x}$$\n\n**Proof Sketch**:\n1. Let $\\{\\vec{e}_1, \\vec{e}_2, \\ldots, \\vec{e}_n\\}$ be the standard basis for $\\mathbb{R}^n$\n2. Define $A$ as the matrix whose columns are $T(\\vec{e}_1), T(\\vec{e}_2), \\ldots, T(\\vec{e}_n)$\n3. For any vector $\\vec{x} = x_1\\vec{e}_1 + x_2\\vec{e}_2 + \\cdots + x_n\\vec{e}_n$:\n   $$T(\\vec{x}) = T(x_1\\vec{e}_1 + x_2\\vec{e}_2 + \\cdots + x_n\\vec{e}_n)$$\n   $$= x_1T(\\vec{e}_1) + x_2T(\\vec{e}_2) + \\cdots + x_nT(\\vec{e}_n)$$\n   $$= A\\vec{x}$$\n\n### Geometric Interpretation\n\nLinear transformations have several important geometric properties:\n- **Preserve lines**: Lines remain lines (though they may be rotated, scaled, or sheared)\n- **Preserve origin**: $T(\\vec{0}) = \\vec{0}$\n- **Preserve parallelism**: Parallel lines remain parallel\n- **Preserve linear combinations**: The image of a linear combination is the linear combination of the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\n\n# Test linearity properties\ndef test_linearity_properties(T_matrix, u, v, c):\n    \"\"\"Test if a matrix represents a linear transformation\"\"\"\n    \n    # Test additivity: T(u + v) = T(u) + T(v)\n    left_side = T_matrix @ (u + v)\n    right_side = (T_matrix @ u) + (T_matrix @ v)\n    additivity_holds = np.allclose(left_side, right_side)\n    \n    # Test homogeneity: T(cu) = cT(u)\n    left_side = T_matrix @ (c * u)\n    right_side = c * (T_matrix @ u)\n    homogeneity_holds = np.allclose(left_side, right_side)\n    \n    # Test zero preservation: T(0) = 0\n    zero_vector = np.zeros_like(u)\n    zero_preserved = np.allclose(T_matrix @ zero_vector, zero_vector)\n    \n    return additivity_holds, homogeneity_holds, zero_preserved\n\n# Example test\ntest_matrix = np.array([[2, 1], [1, 3]])\nu = np.array([1, 2])\nv = np.array([3, 4])\nc = 2.5\n\nadditivity, homogeneity, zero_preserved = test_linearity_properties(test_matrix, u, v, c)\nprint(\"Linear transformation properties:\")\nprint(f\"Additivity: {additivity}\")\nprint(f\"Homogeneity: {homogeneity}\")\nprint(f\"Zero preservation: {zero_preserved}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Common Linear Transformations\n\n### Scaling (Dilation/Contraction)\n\n**Mathematical Definition**: Scaling transforms vectors by multiplying each component by a scalar factor.\n\n**Matrix Form**: For uniform scaling by factor $k$:\n$$S = \\begin{bmatrix} k & 0 \\\\ 0 & k \\end{bmatrix}$$\n\n**Properties**:\n- Preserves angles between vectors\n- Changes lengths by factor $|k|$\n- If $|k| > 1$: dilation (expansion)\n- If $|k| < 1$: contraction (compression)\n- If $k < 0$: reflection through origin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scaling transformations\ndef create_scaling_matrix(scale_x, scale_y=None):\n    \"\"\"Create scaling matrix with different x and y scaling\"\"\"\n    if scale_y is None:\n        scale_y = scale_x  # Uniform scaling\n    return np.array([[scale_x, 0], [0, scale_y]])\n\n# Different types of scaling\nuniform_scale = create_scaling_matrix(2)  # Uniform scaling by 2\nnonuniform_scale = create_scaling_matrix(2, 0.5)  # Scale x by 2, y by 0.5\nreflection = create_scaling_matrix(-1)  # Reflection through origin\n\nprint(\"Uniform scaling matrix (scale by 2):\")\nprint(uniform_scale)\nprint(\"\\nNon-uniform scaling matrix (x×2, y×0.5):\")\nprint(nonuniform_scale)\nprint(\"\\nReflection matrix (scale by -1):\")\nprint(reflection)\n\n# Apply transformations\nv = np.array([1, 1])\nprint(f\"\\nOriginal vector: {v}\")\nprint(f\"Uniformly scaled: {uniform_scale @ v}\")\nprint(f\"Non-uniformly scaled: {nonuniform_scale @ v}\")\nprint(f\"Reflected: {reflection @ v}\")\n\n# Verify properties\nprint(f\"\\nDeterminant of uniform scaling: {np.linalg.det(uniform_scale)}\")\nprint(f\"Area scaling factor: {np.linalg.det(uniform_scale)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Rotation\n\n**Mathematical Definition**: Rotation transforms vectors by rotating them around the origin by a specified angle.\n\n**Matrix Form**: For rotation by angle $\\theta$ (counterclockwise):\n$$R(\\theta) = \\begin{bmatrix} \\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta \\end{bmatrix}$$\n\n**Properties**:\n- Preserves lengths: $|R(\\theta)\\vec{v}| = |\\vec{v}|$\n- Preserves angles between vectors\n- Determinant is 1: $\\det(R(\\theta)) = 1$\n- Inverse is transpose: $R(\\theta)^{-1} = R(\\theta)^T = R(-\\theta)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_rotation_matrix(angle_rad):\n    \"\"\"Create 2D rotation matrix\"\"\"\n    c, s = np.cos(angle_rad), np.sin(angle_rad)\n    return np.array([[c, -s], [s, c]])\n\n# Different rotation angles\nangles_deg = [0, 45, 90, 180, 270]\nangles_rad = [np.radians(angle) for angle in angles_deg]\n\nfor angle_deg, angle_rad in zip(angles_deg, angles_rad):\n    R = create_rotation_matrix(angle_rad)\n    print(f\"\\nRotation matrix ({angle_deg}°):\")\n    print(R)\n    print(f\"Determinant: {np.linalg.det(R):.6f}\")\n    print(f\"R^T × R = I: {np.allclose(R.T @ R, np.eye(2))}\")\n\n# Test rotation properties\nv = np.array([1, 0])\noriginal_length = np.linalg.norm(v)\n\nfor angle_deg, angle_rad in zip([0, 45, 90], angles_rad[:3]):\n    R = create_rotation_matrix(angle_rad)\n    v_rotated = R @ v\n    rotated_length = np.linalg.norm(v_rotated)\n    print(f\"\\n{angle_deg}° rotation:\")\n    print(f\"Original: {v}, length: {original_length:.4f}\")\n    print(f\"Rotated: {v_rotated}, length: {rotated_length:.4f}\")\n    print(f\"Length preserved: {np.isclose(original_length, rotated_length)}\")\n\n# Composition of rotations\nR1 = create_rotation_matrix(np.pi/4)  # 45°\nR2 = create_rotation_matrix(np.pi/6)  # 30°\nR_combined = R1 @ R2  # Rotate by 30° then by 45°\nR_direct = create_rotation_matrix(np.pi/4 + np.pi/6)  # Direct 75° rotation\n\nprint(f\"\\nComposition of rotations:\")\nprint(f\"R(45°) × R(30°) = R(75°): {np.allclose(R_combined, R_direct)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reflection\n\n**Mathematical Definition**: Reflection flips vectors across a specified line or plane.\n\n**Matrix Forms**:\n- Reflection across x-axis: $R_x = \\begin{bmatrix} 1 & 0 \\\\ 0 & -1 \\end{bmatrix}$\n- Reflection across y-axis: $R_y = \\begin{bmatrix} -1 & 0 \\\\ 0 & 1 \\end{bmatrix}$\n- Reflection across line $y = x$: $R_{y=x} = \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix}$\n\n**Properties**:\n- Determinant is -1: $\\det(R) = -1$\n- $R^2 = I$ (applying reflection twice returns to original)\n- Preserves lengths but changes orientation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_reflection_matrices():\n    \"\"\"Create various reflection matrices\"\"\"\n    # Reflection across x-axis\n    R_x = np.array([[1, 0], [0, -1]])\n    \n    # Reflection across y-axis\n    R_y = np.array([[-1, 0], [0, 1]])\n    \n    # Reflection across line y = x\n    R_y_eq_x = np.array([[0, 1], [1, 0]])\n    \n    # Reflection across line y = -x\n    R_y_eq_neg_x = np.array([[0, -1], [-1, 0]])\n    \n    return R_x, R_y, R_y_eq_x, R_y_eq_neg_x\n\nR_x, R_y, R_y_eq_x, R_y_eq_neg_x = create_reflection_matrices()\n\nreflections = {\n    \"Across x-axis\": R_x,\n    \"Across y-axis\": R_y,\n    \"Across y = x\": R_y_eq_x,\n    \"Across y = -x\": R_y_eq_neg_x\n}\n\nfor name, matrix in reflections.items():\n    print(f\"\\n{name}:\")\n    print(matrix)\n    print(f\"Determinant: {np.linalg.det(matrix)}\")\n    print(f\"Matrix² = I: {np.allclose(matrix @ matrix, np.eye(2))}\")\n\n# Test reflection properties\nv = np.array([1, 1])\nprint(f\"\\nOriginal vector: {v}\")\n\nfor name, matrix in reflections.items():\n    v_reflected = matrix @ v\n    print(f\"{name}: {v_reflected}\")\n    print(f\"Length preserved: {np.isclose(np.linalg.norm(v), np.linalg.norm(v_reflected))}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Shear\n\n**Mathematical Definition**: Shear transforms vectors by adding a multiple of one component to another, creating a \"sliding\" effect.\n\n**Matrix Forms**:\n- Horizontal shear: $H_x = \\begin{bmatrix} 1 & k \\\\ 0 & 1 \\end{bmatrix}$\n- Vertical shear: $H_y = \\begin{bmatrix} 1 & 0 \\\\ k & 1 \\end{bmatrix}$\n\n**Properties**:\n- Determinant is 1: $\\det(H) = 1$ (preserves area)\n- Preserves lines parallel to the shear direction\n- Changes angles between vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_shear_matrices(shear_factor):\n    \"\"\"Create horizontal and vertical shear matrices\"\"\"\n    # Horizontal shear (shear in x-direction)\n    H_x = np.array([[1, shear_factor], [0, 1]])\n    \n    # Vertical shear (shear in y-direction)\n    H_y = np.array([[1, 0], [shear_factor, 1]])\n    \n    return H_x, H_y\n\nshear_factor = 0.5\nH_x, H_y = create_shear_matrices(shear_factor)\n\nprint(\"Horizontal shear matrix:\")\nprint(H_x)\nprint(f\"Determinant: {np.linalg.det(H_x)}\")\n\nprint(\"\\nVertical shear matrix:\")\nprint(H_y)\nprint(f\"Determinant: {np.linalg.det(H_y)}\")\n\n# Apply shear transformations\nv = np.array([1, 1])\nprint(f\"\\nOriginal vector: {v}\")\nprint(f\"Horizontal shear: {H_x @ v}\")\nprint(f\"Vertical shear: {H_y @ v}\")\n\n# Verify area preservation\noriginal_area = 1  # Unit square\nsheared_area = np.linalg.det(H_x) * original_area\nprint(f\"\\nOriginal area: {original_area}\")\nprint(f\"Sheared area: {sheared_area}\")\nprint(f\"Area preserved: {np.isclose(original_area, sheared_area)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Composition of Transformations\n\n**Mathematical Principle**: Linear transformations can be combined by matrix multiplication. The composition of transformations $T_1$ and $T_2$ is given by:\n$$(T_2 \\circ T_1)(\\vec{x}) = T_2(T_1(\\vec{x})) = A_2(A_1\\vec{x}) = (A_2A_1)\\vec{x}$$\n\n**Important Note**: Matrix multiplication is not commutative, so the order of transformations matters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Composition of transformations\ndef compose_transformations(*matrices):\n    \"\"\"Compose multiple transformations by matrix multiplication\"\"\"\n    result = matrices[0]\n    for matrix in matrices[1:]:\n        result = matrix @ result\n    return result\n\n# Example: Scale then rotate\nscale_matrix = create_scaling_matrix(2)\nrotation_matrix = create_rotation_matrix(np.pi/4)\n\n# Scale then rotate\nscale_then_rotate = rotation_matrix @ scale_matrix\n# Rotate then scale\nrotate_then_scale = scale_matrix @ rotation_matrix\n\nprint(\"Scale then rotate:\")\nprint(scale_then_rotate)\nprint(\"\\nRotate then scale:\")\nprint(rotate_then_scale)\nprint(f\"\\nOrder matters: {not np.allclose(scale_then_rotate, rotate_then_scale)}\")\n\n# Test on a vector\nv = np.array([1, 0])\nprint(f\"\\nOriginal vector: {v}\")\nprint(f\"Scale then rotate: {scale_then_rotate @ v}\")\nprint(f\"Rotate then scale: {rotate_then_scale @ v}\")\n\n# Multiple transformations\nshear_matrix = create_shear_matrices(0.3)[0]  # Horizontal shear\ncombined = compose_transformations(scale_matrix, rotation_matrix, shear_matrix)\nprint(f\"\\nCombined transformation (scale → rotate → shear):\")\nprint(combined)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Properties of Linear Transformations\n\n### Determinant and Area/Volume Scaling\n\n**Key Property**: The determinant of a transformation matrix tells us how it affects area (in 2D) or volume (in 3D).\n\n- $|\\det(A)| = 1$: Preserves area/volume\n- $|\\det(A)| > 1$: Expands area/volume\n- $|\\det(A)| < 1$: Contracts area/volume\n- $\\det(A) < 0$: Changes orientation (reflection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_transformation_properties(matrix, name):\n    \"\"\"Analyze properties of a transformation matrix\"\"\"\n    det = np.linalg.det(matrix)\n    trace = np.trace(matrix)\n    \n    print(f\"\\n{name}:\")\n    print(f\"Matrix:\\n{matrix}\")\n    print(f\"Determinant: {det:.4f}\")\n    print(f\"Trace: {trace:.4f}\")\n    \n    if abs(det) == 1:\n        print(\"Area/volume preserving\")\n    elif abs(det) > 1:\n        print(f\"Expands area/volume by factor {abs(det):.2f}\")\n    else:\n        print(f\"Contracts area/volume by factor {abs(det):.2f}\")\n    \n    if det < 0:\n        print(\"Changes orientation (reflection)\")\n    else:\n        print(\"Preserves orientation\")\n    \n    # Check if orthogonal (rotation/reflection)\n    is_orthogonal = np.allclose(matrix.T @ matrix, np.eye(matrix.shape[0]))\n    if is_orthogonal:\n        print(\"Orthogonal transformation (rotation or reflection)\")\n    \n    return det, trace\n\n# Analyze different transformations\ntransformations = {\n    \"Identity\": np.eye(2),\n    \"Scaling (2x)\": create_scaling_matrix(2),\n    \"Rotation (45°)\": create_rotation_matrix(np.pi/4),\n    \"Reflection (x-axis)\": np.array([[1, 0], [0, -1]]),\n    \"Shear (0.5)\": np.array([[1, 0.5], [0, 1]]),\n    \"Non-uniform scaling\": create_scaling_matrix(2, 0.5)\n}\n\nfor name, matrix in transformations.items():\n    analyze_transformation_properties(matrix, name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Eigenvalues and Eigenvectors\n\n**Definition**: For a linear transformation $T$ represented by matrix $A$, a non-zero vector $\\vec{v}$ is an eigenvector with eigenvalue $\\lambda$ if:\n$$A\\vec{v} = \\lambda\\vec{v}$$\n\n**Geometric Interpretation**:\n- Eigenvectors are vectors that don't change direction under the transformation\n- Eigenvalues tell us how much these vectors are scaled\n- The eigenvectors form a basis that diagonalizes the transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_eigenproperties(matrix, name):\n    \"\"\"Analyze eigenvalues and eigenvectors of a transformation\"\"\"\n    eigenvalues, eigenvectors = np.linalg.eig(matrix)\n    \n    print(f\"\\n{name} - Eigenanalysis:\")\n    print(f\"Eigenvalues: {eigenvalues}\")\n    print(f\"Eigenvectors:\")\n    for i, (eigenval, eigenvec) in enumerate(zip(eigenvalues, eigenvectors.T)):\n        print(f\"  λ{i+1} = {eigenval:.4f}: {eigenvec}\")\n    \n    # Verify eigenvalue equation\n    for i, (eigenval, eigenvec) in enumerate(zip(eigenvalues, eigenvectors.T)):\n        left_side = matrix @ eigenvec\n        right_side = eigenval * eigenvec\n        verification = np.allclose(left_side, right_side)\n        print(f\"  Verification for λ{i+1}: {verification}\")\n    \n    return eigenvalues, eigenvectors\n\n# Analyze eigenproperties of different transformations\nfor name, matrix in transformations.items():\n    analyze_eigenproperties(matrix, name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Applications in AI/ML\n\n### Neural Network Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def neural_network_layer_analysis():\n    \"\"\"Analyze linear transformations in neural networks\"\"\"\n    \n    # Simulate a neural network layer\n    input_size = 4\n    output_size = 3\n    batch_size = 5\n    \n    # Weight matrix (linear transformation)\n    W = np.random.randn(input_size, output_size) * 0.1\n    b = np.zeros(output_size)  # Bias vector\n    \n    # Input data\n    X = np.random.randn(batch_size, input_size)\n    \n    # Forward pass (linear transformation + bias)\n    Z = X @ W + b\n    \n    print(\"Neural Network Layer Analysis:\")\n    print(f\"Input shape: {X.shape}\")\n    print(f\"Weight matrix shape: {W.shape}\")\n    print(f\"Output shape: {Z.shape}\")\n    \n    # Analyze the linear transformation\n    print(f\"\\nWeight matrix properties:\")\n    print(f\"Rank: {np.linalg.matrix_rank(W)}\")\n    print(f\"Condition number: {np.linalg.cond(W):.2f}\")\n    \n    # Singular value decomposition\n    U, S, Vt = np.linalg.svd(W)\n    print(f\"Singular values: {S}\")\n    print(f\"Effective rank: {np.sum(S > 1e-10)}\")\n    \n    return W, X, Z\n\nW, X, Z = neural_network_layer_analysis()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Principal Component Analysis (PCA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pca_analysis():\n    \"\"\"Demonstrate PCA as a linear transformation\"\"\"\n    \n    # Generate sample data\n    np.random.seed(42)\n    n_samples = 100\n    n_features = 3\n    \n    # Create correlated data\n    data = np.random.multivariate_normal([0, 0, 0], \n                                       [[1, 0.8, 0.6], \n                                        [0.8, 1, 0.7], \n                                        [0.6, 0.7, 1]], \n                                       n_samples)\n    \n    # Center the data\n    data_centered = data - np.mean(data, axis=0)\n    \n    # Compute covariance matrix\n    cov_matrix = np.cov(data_centered.T)\n    \n    # Eigendecomposition\n    eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n    \n    # Sort by eigenvalues (descending)\n    sorted_indices = np.argsort(eigenvalues)[::-1]\n    eigenvalues = eigenvalues[sorted_indices]\n    eigenvectors = eigenvectors[:, sorted_indices]\n    \n    print(\"PCA Analysis:\")\n    print(f\"Original data shape: {data.shape}\")\n    print(f\"Eigenvalues: {eigenvalues}\")\n    print(f\"Explained variance ratio: {eigenvalues / np.sum(eigenvalues)}\")\n    \n    # Project data onto principal components\n    data_pca = data_centered @ eigenvectors\n    \n    print(f\"\\nTransformed data shape: {data_pca.shape}\")\n    print(f\"Variance in each component: {np.var(data_pca, axis=0)}\")\n    \n    return data, data_pca, eigenvectors, eigenvalues\n\ndata, data_pca, eigenvectors, eigenvalues = pca_analysis()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization of Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_transformations():\n    \"\"\"Comprehensive visualization of linear transformations\"\"\"\n    \n    # Create unit square and unit vectors\n    unit_square = np.array([[0, 1, 1, 0, 0], [0, 0, 1, 1, 0]])\n    unit_vectors = [np.array([1, 0]), np.array([0, 1])]\n    \n    # Define transformations\n    transformations = {\n        \"Identity\": np.eye(2),\n        \"Scaling (2x)\": create_scaling_matrix(2),\n        \"Rotation (45°)\": create_rotation_matrix(np.pi/4),\n        \"Reflection (x-axis)\": np.array([[1, 0], [0, -1]]),\n        \"Shear (0.5)\": np.array([[1, 0.5], [0, 1]]),\n        \"Non-uniform scaling\": create_scaling_matrix(2, 0.5)\n    }\n    \n    # Create subplots\n    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n    axes = axes.flatten()\n    \n    for i, (name, matrix) in enumerate(transformations.items()):\n        ax = axes[i]\n        \n        # Original unit square\n        ax.plot(unit_square[0], unit_square[1], 'b-', linewidth=2, label='Original')\n        \n        # Transformed unit square\n        transformed_square = matrix @ unit_square\n        ax.plot(transformed_square[0], transformed_square[1], 'r-', linewidth=2, label='Transformed')\n        \n        # Unit vectors\n        for j, vector in enumerate(unit_vectors):\n            ax.quiver(0, 0, vector[0], vector[1], angles='xy', scale_units='xy', scale=1,\n                     color='blue', alpha=0.5, width=0.02)\n            transformed_vector = matrix @ vector\n            ax.quiver(0, 0, transformed_vector[0], transformed_vector[1], angles='xy', scale_units='xy', scale=1,\n                     color='red', alpha=0.7, width=0.02)\n        \n        ax.set_xlim(-2, 3)\n        ax.set_ylim(-2, 3)\n        ax.grid(True, alpha=0.3)\n        ax.set_aspect('equal')\n        ax.set_title(f'{name}\\nDet: {np.linalg.det(matrix):.2f}')\n        ax.legend()\n    \n    plt.tight_layout()\n    plt.show()\n\nvisualize_transformations()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercises\n\n### Exercise 1: Linear Transformation Properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify linear transformation properties\ndef verify_linearity():\n    A = np.array([[2, 1], [1, 3]])\n    u = np.array([1, 2])\n    v = np.array([3, 4])\n    c = 2.5\n    \n    # Test additivity\n    additivity = np.allclose(A @ (u + v), A @ u + A @ v)\n    print(f\"Additivity: {additivity}\")\n    \n    # Test homogeneity\n    homogeneity = np.allclose(A @ (c * u), c * (A @ u))\n    print(f\"Homogeneity: {homogeneity}\")\n    \n    # Test zero preservation\n    zero_preservation = np.allclose(A @ np.zeros(2), np.zeros(2))\n    print(f\"Zero preservation: {zero_preservation}\")\n    \n    return additivity and homogeneity and zero_preservation\n\nverify_linearity()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 2: Transformation Composition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Study the effect of transformation order\ndef composition_order_effects():\n    # Define transformations\n    scale = create_scaling_matrix(2)\n    rotate = create_rotation_matrix(np.pi/6)  # 30 degrees\n    shear = np.array([[1, 0.5], [0, 1]])\n    \n    # Test vector\n    v = np.array([1, 1])\n    \n    # Different compositions\n    T1 = scale @ rotate @ shear  # Scale → Rotate → Shear\n    T2 = rotate @ scale @ shear  # Rotate → Scale → Shear\n    T3 = shear @ rotate @ scale  # Shear → Rotate → Scale\n    \n    print(\"Transformation compositions:\")\n    print(f\"Scale → Rotate → Shear: {T1 @ v}\")\n    print(f\"Rotate → Scale → Shear: {T2 @ v}\")\n    print(f\"Shear → Rotate → Scale: {T3 @ v}\")\n    \n    # Check if results are different\n    results_different = not (np.allclose(T1 @ v, T2 @ v) and np.allclose(T2 @ v, T3 @ v))\n    print(f\"Order matters: {results_different}\")\n\ncomposition_order_effects()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 3: Eigenvalue Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze eigenvalues of different transformations\ndef eigenvalue_analysis():\n    transformations = {\n        \"Scaling (2x)\": create_scaling_matrix(2),\n        \"Rotation (45°)\": create_rotation_matrix(np.pi/4),\n        \"Reflection\": np.array([[1, 0], [0, -1]]),\n        \"Shear\": np.array([[1, 0.5], [0, 1]])\n    }\n    \n    for name, matrix in transformations.items():\n        eigenvalues, eigenvectors = np.linalg.eig(matrix)\n        print(f\"\\n{name}:\")\n        print(f\"Eigenvalues: {eigenvalues}\")\n        print(f\"Product of eigenvalues: {np.prod(eigenvalues):.4f}\")\n        print(f\"Determinant: {np.linalg.det(matrix):.4f}\")\n        print(f\"Sum of eigenvalues: {np.sum(eigenvalues):.4f}\")\n        print(f\"Trace: {np.trace(matrix):.4f}\")\n\neigenvalue_analysis()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n\nIn this chapter, we've covered:\n\n1. **Linear Transformation Fundamentals**: Definition, properties, and matrix representation\n2. **Common Transformations**: Scaling, rotation, reflection, and shear with detailed mathematical foundations\n3. **Transformation Composition**: How to combine transformations and why order matters\n4. **Geometric Properties**: Determinant interpretation, eigenvalue analysis, and area/volume scaling\n5. **AI/ML Applications**: Neural networks, PCA, and dimensionality reduction\n6. **Visualization**: Comprehensive plotting of transformation effects\n\n### Key Takeaways:\n- Linear transformations preserve linear combinations and have important geometric properties\n- Every linear transformation can be represented by a matrix\n- The determinant tells us about area/volume scaling and orientation changes\n- Eigenvalues and eigenvectors reveal the fundamental behavior of transformations\n- Understanding linear transformations is crucial for neural networks and dimensionality reduction\n\n### Next Steps:\nIn the next chapter, we'll explore eigenvalues and eigenvectors in detail, understanding how they reveal the fundamental structure of matrices and transformations."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}