{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Integration\n\n[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)\n[![NumPy](https://img.shields.io/badge/NumPy-1.21+-green.svg)](https://numpy.org/)\n[![Matplotlib](https://img.shields.io/badge/Matplotlib-3.5+-orange.svg)](https://matplotlib.org/)\n[![SymPy](https://img.shields.io/badge/SymPy-1.10+-purple.svg)](https://www.sympy.org/)\n[![SciPy](https://img.shields.io/badge/SciPy-1.7+-red.svg)](https://scipy.org/)\n\n## Introduction\n\nIntegration is the reverse process of differentiation and is essential for calculating areas, volumes, and cumulative effects. In machine learning, integration is used for probability calculations, expected values, and continuous optimization.\n\n### Why Integration Matters in AI/ML\n\nIntegration plays a crucial role in machine learning and data science:\n\n1. **Probability Theory**: Computing probabilities, expected values, and cumulative distribution functions\n2. **Bayesian Inference**: Marginalization and evidence computation\n3. **Continuous Optimization**: Area under curves, cumulative effects\n4. **Signal Processing**: Fourier transforms and spectral analysis\n5. **Neural Networks**: Activation function integrals and normalization\n\n### Mathematical Foundation\n\nIntegration can be understood in two complementary ways:\n\n1. **Antiderivative**: If F'(x) = f(x), then F(x) is an antiderivative of f(x)\n2. **Area Under Curve**: The definite integral ∫ₐᵇ f(x) dx represents the signed area between the curve y = f(x) and the x-axis from x = a to x = b\n\n### Fundamental Theorem of Calculus\n\nThe fundamental theorem connects differentiation and integration:\n\n**Part 1**: If F(x) = ∫ₐˣ f(t) dt, then F'(x) = f(x)\n\n**Part 2**: If F(x) is any antiderivative of f(x), then ∫ₐᵇ f(x) dx = F(b) - F(a)\n\nThis theorem is the foundation that makes integration computationally tractable.\n\n## 4.1 Antiderivatives and Indefinite Integrals\n\nThe indefinite integral finds the antiderivative of a function. Unlike definite integrals, indefinite integrals include an arbitrary constant of integration.\n\n### Mathematical Definition\n\nThe indefinite integral of f(x) is:\n\n$$\\int f(x) dx = F(x) + C$$\n\nwhere F'(x) = f(x) and C is the constant of integration.\n\n### Key Properties\n\n1. **Linearity**: ∫(af(x) + bg(x)) dx = a∫f(x) dx + b∫g(x) dx\n2. **Power Rule**: ∫xⁿ dx = xⁿ⁺¹/(n+1) + C (for n ≠ -1)\n3. **Exponential**: ∫eˣ dx = eˣ + C\n4. **Trigonometric**: ∫sin(x) dx = -cos(x) + C, ∫cos(x) dx = sin(x) + C\n\n### Why the Constant of Integration Matters\n\nThe constant C represents the fact that any function differing by a constant has the same derivative. This is crucial for:\n- Initial value problems\n- Boundary conditions\n- Physical interpretations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nimport sympy as sp\nfrom scipy import integrate\n\n# Comprehensive antiderivative demonstration\ndef demonstrate_antiderivatives_comprehensive():\n    x = sp.Symbol('x')\n    \n    print(\"=== ANTIDERIVATIVE EXAMPLES ===\\n\")\n    \n    # Basic power functions\n    print(\"1. POWER FUNCTIONS\")\n    power_examples = [x**0, x**1, x**2, x**3, x**(-1), x**(-2)]\n    for expr in power_examples:\n        integral = sp.integrate(expr, x)\n        print(f\"   ∫ {expr} dx = {integral}\")\n    \n    # Exponential and logarithmic functions\n    print(\"\\n2. EXPONENTIAL AND LOGARITHMIC FUNCTIONS\")\n    exp_expr = sp.exp(x)\n    log_expr = sp.log(x)\n    print(f\"   ∫ {exp_expr} dx = {sp.integrate(exp_expr, x)}\")\n    print(f\"   ∫ {log_expr} dx = {sp.integrate(log_expr, x)}\")\n    \n    # Trigonometric functions\n    print(\"\\n3. TRIGONOMETRIC FUNCTIONS\")\n    trig_examples = [sp.sin(x), sp.cos(x), sp.tan(x), 1/sp.cos(x)**2]\n    for expr in trig_examples:\n        integral = sp.integrate(expr, x)\n        print(f\"   ∫ {expr} dx = {integral}\")\n    \n    # Composite functions\n    print(\"\\n4. COMPOSITE FUNCTIONS\")\n    composite_examples = [\n        sp.sin(x**2) * x,  # Requires substitution\n        sp.exp(x**2) * x,  # Requires substitution\n        sp.log(x) / x,     # Requires substitution\n        sp.sin(x) * sp.cos(x)  # Requires trigonometric identity\n    ]\n    \n    for expr in composite_examples:\n        try:\n            integral = sp.integrate(expr, x)\n            print(f\"   ∫ {expr} dx = {integral}\")\n        except:\n            print(f\"   ∫ {expr} dx = (requires advanced techniques)\")\n\ndemonstrate_antiderivatives_comprehensive()\n\n# Visualize antiderivatives with multiple constants\ndef visualize_antiderivatives():\n    def f(x):\n        return x**2\n    \n    def F(x, C=0):\n        return x**3 / 3 + C\n    \n    x_vals = np.linspace(-2, 2, 100)\n    y_vals = f(x_vals)\n    \n    # Multiple antiderivatives with different constants\n    constants = [-2, -1, 0, 1, 2]\n    colors = ['red', 'orange', 'blue', 'green', 'purple']\n    \n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n    \n    # Original function\n    ax1.plot(x_vals, y_vals, 'b-', linewidth=3, label='f(x) = x²')\n    ax1.set_xlabel('x')\n    ax1.set_ylabel('f(x)')\n    ax1.set_title('Original Function')\n    ax1.legend()\n    ax1.grid(True, alpha=0.3)\n    \n    # Antiderivatives\n    for i, (C, color) in enumerate(zip(constants, colors)):\n        Y_vals = F(x_vals, C)\n        ax2.plot(x_vals, Y_vals, color=color, linewidth=2, \n                label=f'F(x) = x³/3 + {C}')\n    \n    ax2.set_xlabel('x')\n    ax2.set_ylabel('F(x)')\n    ax2.set_title('Antiderivatives (Different Constants)')\n    ax2.legend()\n    ax2.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Demonstrate that all antiderivatives have the same derivative\n    print(\"\\nVerification: All antiderivatives have the same derivative\")\n    x_test = 1.0\n    for C in constants:\n        # Numerical derivative of antiderivative\n        h = 1e-7\n        derivative = (F(x_test + h, C) - F(x_test - h, C)) / (2 * h)\n        print(f\"  F(x) = x³/3 + {C}: F'({x_test}) = {derivative:.6f}\")\n\nvisualize_antiderivatives()\n\n# Advanced antiderivative examples\ndef advanced_antiderivative_examples():\n    x = sp.Symbol('x')\n    \n    print(\"\\n=== ADVANCED ANTIDERIVATIVE EXAMPLES ===\\n\")\n    \n    # Rational functions\n    print(\"1. RATIONAL FUNCTIONS\")\n    rational_examples = [\n        1 / (x + 1),\n        1 / (x**2 + 1),\n        x / (x**2 + 1),\n        1 / (x**2 - 1)\n    ]\n    \n    for expr in rational_examples:\n        try:\n            integral = sp.integrate(expr, x)\n            print(f\"   ∫ {expr} dx = {integral}\")\n        except:\n            print(f\"   ∫ {expr} dx = (complex result)\")\n    \n    # Exponential combinations\n    print(\"\\n2. EXPONENTIAL COMBINATIONS\")\n    exp_examples = [\n        sp.exp(x) * sp.sin(x),\n        sp.exp(x) * sp.cos(x),\n        x * sp.exp(x),\n        x**2 * sp.exp(x)\n    ]\n    \n    for expr in exp_examples:\n        integral = sp.integrate(expr, x)\n        print(f\"   ∫ {expr} dx = {integral}\")\n    \n    # Trigonometric combinations\n    print(\"\\n3. TRIGONOMETRIC COMBINATIONS\")\n    trig_examples = [\n        sp.sin(x)**2,\n        sp.cos(x)**2,\n        sp.sin(x) * sp.cos(x),\n        sp.sin(x)**3\n    ]\n    \n    for expr in trig_examples:\n        integral = sp.integrate(expr, x)\n        print(f\"   ∫ {expr} dx = {integral}\")\n\nadvanced_antiderivative_examples()\n\n# Numerical verification of antiderivatives\ndef numerical_verification():\n    print(\"\\n=== NUMERICAL VERIFICATION ===\\n\")\n    \n    def f(x):\n        return x**2\n    \n    def F(x, C=0):\n        return x**3 / 3 + C\n    \n    def numerical_derivative(F, x, h=1e-7):\n        return (F(x + h) - F(x - h)) / (2 * h)\n    \n    # Test points\n    test_points = [0.5, 1.0, 1.5, 2.0]\n    \n    print(\"Verifying that F'(x) = f(x):\")\n    for x_test in test_points:\n        # Analytical derivative of antiderivative\n        analytical_deriv = f(x_test)\n        \n        # Numerical derivative of antiderivative\n        numerical_deriv = numerical_derivative(lambda x: F(x, 0), x_test)\n        \n        error = abs(analytical_deriv - numerical_deriv)\n        print(f\"  x = {x_test}: f(x) = {analytical_deriv:.6f}, F'(x) = {numerical_deriv:.6f}, error = {error:.2e}\")\n\nnumerical_verification()\n\n# Physical interpretation of antiderivatives\ndef physical_interpretation():\n    print(\"\\n=== PHYSICAL INTERPRETATION ===\\n\")\n    \n    # Example: Position, velocity, and acceleration\n    def acceleration(t):\n        return 2 * t  # a(t) = 2t\n    \n    def velocity(t, v0=0):\n        return t**2 + v0  # v(t) = ∫a(t)dt = t² + v₀\n    \n    def position(t, x0=0, v0=0):\n        return t**3 / 3 + v0 * t + x0  # x(t) = ∫v(t)dt = t³/3 + v₀t + x₀\n    \n    # Test time points\n    t_vals = np.linspace(0, 5, 100)\n    \n    # Calculate values\n    a_vals = [acceleration(t) for t in t_vals]\n    v_vals = [velocity(t) for t in t_vals]\n    x_vals = [position(t) for t in t_vals]\n    \n    # Visualization\n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n    \n    ax1.plot(t_vals, a_vals, 'r-', linewidth=2)\n    ax1.set_xlabel('Time (s)')\n    ax1.set_ylabel('Acceleration (m/s²)')\n    ax1.set_title('Acceleration: a(t) = 2t')\n    ax1.grid(True, alpha=0.3)\n    \n    ax2.plot(t_vals, v_vals, 'g-', linewidth=2)\n    ax2.set_xlabel('Time (s)')\n    ax2.set_ylabel('Velocity (m/s)')\n    ax2.set_title('Velocity: v(t) = t²')\n    ax2.grid(True, alpha=0.3)\n    \n    ax3.plot(t_vals, x_vals, 'b-', linewidth=2)\n    ax3.set_xlabel('Time (s)')\n    ax3.set_ylabel('Position (m)')\n    ax3.set_title('Position: x(t) = t³/3')\n    ax3.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Verify relationships\n    print(\"Physical relationships:\")\n    t_test = 2.0\n    print(f\"  At t = {t_test}s:\")\n    print(f\"    Acceleration: a({t_test}) = {acceleration(t_test)} m/s²\")\n    print(f\"    Velocity: v({t_test}) = {velocity(t_test)} m/s\")\n    print(f\"    Position: x({t_test}) = {position(t_test)} m\")\n    print(f\"    Verification: v'({t_test}) = {acceleration(t_test)} ✓\")\n    print(f\"    Verification: x'({t_test}) = {velocity(t_test)} ✓\")\n\nphysical_interpretation()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Applications in Machine Learning\n\nAntiderivatives are fundamental to:\n\n1. **Activation Functions**: Computing integrals of activation functions for normalization\n2. **Loss Functions**: Understanding cumulative loss over time\n3. **Probability Distributions**: Computing cumulative distribution functions\n4. **Signal Processing**: Fourier transforms and spectral analysis\n5. **Optimization**: Understanding cumulative effects in gradient-based methods\n\n## 4.2 Definite Integrals\n\nDefinite integrals calculate the area under a curve between two points. They represent the net accumulation of a quantity over an interval and are fundamental to many applications in science and engineering.\n\n### Mathematical Definition\n\nThe definite integral of f(x) from a to b is:\n\n$$\\int_a^b f(x) dx = \\lim_{n \\to \\infty} \\sum_{i=1}^n f(x_i) \\Delta x$$\n\nwhere Δx = (b-a)/n and xᵢ are sample points in the interval [a, b].\n\n### Geometric Interpretation\n\n- **Positive Area**: When f(x) ≥ 0, the integral represents the area between the curve and the x-axis\n- **Negative Area**: When f(x) ≤ 0, the integral represents the negative of the area\n- **Net Area**: The definite integral gives the net signed area (positive minus negative)\n\n### Fundamental Theorem of Calculus (Part 2)\n\nIf F(x) is any antiderivative of f(x), then:\n\n$$\\int_a^b f(x) dx = F(b) - F(a) = [F(x)]_a^b$$\n\nThis provides a powerful computational method for evaluating definite integrals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive definite integration demonstration\ndef definite_integration_comprehensive():\n    x = sp.Symbol('x')\n    \n    print(\"=== DEFINITE INTEGRATION EXAMPLES ===\\n\")\n    \n    # Basic examples\n    print(\"1. BASIC EXAMPLES\")\n    \n    # ∫₀¹ x² dx = [x³/3]₀¹ = 1/3\n    integral1 = sp.integrate(x**2, (x, 0, 1))\n    print(f\"   ∫₀¹ x² dx = {integral1}\")\n    \n    # ∫₀^π sin(x) dx = [-cos(x)]₀^π = 2\n    integral2 = sp.integrate(sp.sin(x), (x, 0, sp.pi))\n    print(f\"   ∫₀^π sin(x) dx = {integral2}\")\n    \n    # ∫₀^∞ e^(-x) dx = [-e^(-x)]₀^∞ = 1\n    integral3 = sp.integrate(sp.exp(-x), (x, 0, sp.oo))\n    print(f\"   ∫₀^∞ e^(-x) dx = {integral3}\")\n    \n    # ∫₋₁¹ x³ dx = [x⁴/4]₋₁¹ = 0 (odd function over symmetric interval)\n    integral4 = sp.integrate(x**3, (x, -1, 1))\n    print(f\"   ∫₋₁¹ x³ dx = {integral4}\")\n    \n    # Area calculations\n    print(\"\\n2. AREA CALCULATIONS\")\n    \n    # Area under y = x² from 0 to 2\n    area1 = sp.integrate(x**2, (x, 0, 2))\n    print(f\"   Area under y = x² from 0 to 2: {area1}\")\n    \n    # Area between y = x and y = x² from 0 to 1\n    area2 = sp.integrate(x - x**2, (x, 0, 1))\n    print(f\"   Area between y = x and y = x² from 0 to 1: {area2}\")\n    \n    # Improper integrals\n    print(\"\\n3. IMPROPER INTEGRALS\")\n    \n    # ∫₀^∞ e^(-x) dx = 1\n    improper1 = sp.integrate(sp.exp(-x), (x, 0, sp.oo))\n    print(f\"   ∫₀^∞ e^(-x) dx = {improper1}\")\n    \n    # ∫₋∞^∞ e^(-x²/2) dx = √(2π)\n    improper2 = sp.integrate(sp.exp(-x**2/2), (x, -sp.oo, sp.oo))\n    print(f\"   ∫₋∞^∞ e^(-x²/2) dx = {improper2}\")\n    \n    # ∫₁^∞ 1/x² dx = 1\n    improper3 = sp.integrate(1/x**2, (x, 1, sp.oo))\n    print(f\"   ∫₁^∞ 1/x² dx = {improper3}\")\n\ndefinite_integration_comprehensive()\n\n# Advanced numerical integration with error analysis\ndef numerical_integration_advanced():\n    print(\"\\n=== NUMERICAL INTEGRATION ANALYSIS ===\\n\")\n    \n    # Test functions\n    def f1(x): return x**2\n    def f2(x): return np.sin(x)\n    def f3(x): return np.exp(-x)\n    def f4(x): return 1 / (1 + x**2)\n    \n    # Integration intervals\n    intervals = [\n        (f1, 0, 1, \"∫₀¹ x² dx\", 1/3),\n        (f2, 0, np.pi, \"∫₀^π sin(x) dx\", 2),\n        (f3, 0, np.inf, \"∫₀^∞ e^(-x) dx\", 1),\n        (f4, 0, 1, \"∫₀¹ 1/(1+x²) dx\", np.pi/4)\n    ]\n    \n    print(\"Function\\t\\tExact\\t\\tNumerical\\tError\")\n    print(\"-\" * 60)\n    \n    for func, a, b, name, exact in intervals:\n        if b == np.inf:\n            result, error = integrate.quad(func, a, b)\n        else:\n            result, error = integrate.quad(func, a, b)\n        \n        abs_error = abs(result - exact)\n        rel_error = abs_error / abs(exact) if exact != 0 else abs_error\n        \n        print(f\"{name}\\t{exact:.6f}\\t{result:.6f}\\t{abs_error:.2e}\")\n        print(f\"  Estimated error: {error:.2e}\")\n        print(f\"  Relative error: {rel_error:.2e}\")\n        print()\n\nnumerical_integration_advanced()\n\n# Comprehensive visualization of definite integrals\ndef visualize_definite_integrals():\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n    \n    # Example 1: Positive area\n    x1 = np.linspace(0, 1, 1000)\n    y1 = x1**2\n    \n    ax1.fill_between(x1, y1, alpha=0.3, color='blue')\n    ax1.plot(x1, y1, 'b-', linewidth=2, label='f(x) = x²')\n    ax1.set_xlabel('x')\n    ax1.set_ylabel('f(x)')\n    ax1.set_title('∫₀¹ x² dx = 1/3 (Positive Area)')\n    ax1.legend()\n    ax1.grid(True, alpha=0.3)\n    \n    # Example 2: Negative area\n    x2 = np.linspace(0, np.pi, 1000)\n    y2 = -np.sin(x2)\n    \n    ax2.fill_between(x2, y2, alpha=0.3, color='red')\n    ax2.plot(x2, y2, 'r-', linewidth=2, label='f(x) = -sin(x)')\n    ax2.set_xlabel('x')\n    ax2.set_ylabel('f(x)')\n    ax2.set_title('∫₀^π -sin(x) dx = -2 (Negative Area)')\n    ax2.legend()\n    ax2.grid(True, alpha=0.3)\n    \n    # Example 3: Net area (positive and negative)\n    x3 = np.linspace(0, 2*np.pi, 1000)\n    y3 = np.sin(x3)\n    \n    # Separate positive and negative regions\n    positive_mask = y3 >= 0\n    negative_mask = y3 < 0\n    \n    ax3.fill_between(x3[positive_mask], y3[positive_mask], alpha=0.3, color='green')\n    ax3.fill_between(x3[negative_mask], y3[negative_mask], alpha=0.3, color='red')\n    ax3.plot(x3, y3, 'b-', linewidth=2, label='f(x) = sin(x)')\n    ax3.set_xlabel('x')\n    ax3.set_ylabel('f(x)')\n    ax3.set_title('∫₀^{2π} sin(x) dx = 0 (Net Area)')\n    ax3.legend()\n    ax3.grid(True, alpha=0.3)\n    \n    # Example 4: Area between curves\n    x4 = np.linspace(0, 1, 1000)\n    y4_upper = x4\n    y4_lower = x4**2\n    \n    ax4.fill_between(x4, y4_upper, y4_lower, alpha=0.3, color='purple')\n    ax4.plot(x4, y4_upper, 'b-', linewidth=2, label='y = x')\n    ax4.plot(x4, y4_lower, 'r-', linewidth=2, label='y = x²')\n    ax4.set_xlabel('x')\n    ax4.set_ylabel('y')\n    ax4.set_title('Area between y = x and y = x²')\n    ax4.legend()\n    ax4.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n\nvisualize_definite_integrals()\n\n# Riemann sum approximation\ndef riemann_sum_analysis():\n    print(\"\\n=== RIEMANN SUM ANALYSIS ===\\n\")\n    \n    def f(x):\n        return x**2\n    \n    def riemann_sum(f, a, b, n, method='left'):\n        \"\"\"Compute Riemann sum using specified method\"\"\"\n        x = np.linspace(a, b, n+1)\n        h = (b - a) / n\n        \n        if method == 'left':\n            x_points = x[:-1]\n        elif method == 'right':\n            x_points = x[1:]\n        elif method == 'midpoint':\n            x_points = (x[:-1] + x[1:]) / 2\n        elif method == 'trapezoidal':\n            return h * (0.5 * f(x[0]) + np.sum(f(x[1:-1])) + 0.5 * f(x[-1]))\n        \n        return h * np.sum(f(x_points))\n    \n    # Test different methods and numbers of subintervals\n    a, b = 0, 1\n    exact = 1/3\n    \n    methods = ['left', 'right', 'midpoint', 'trapezoidal']\n    n_values = [10, 50, 100, 500]\n    \n    print(\"Method\\t\\tN=10\\t\\tN=50\\t\\tN=100\\t\\tN=500\")\n    print(\"-\" * 80)\n    \n    for method in methods:\n        results = []\n        for n in n_values:\n            result = riemann_sum(f, a, b, n, method)\n            results.append(result)\n        \n        errors = [abs(r - exact) for r in results]\n        print(f\"{method:12s}\", end=\"\")\n        for result in results:\n            print(f\"{result:.6f}\\t\", end=\"\")\n        print()\n        print(f\"{'Error':12s}\", end=\"\")\n        for error in errors:\n            print(f\"{error:.2e}\\t\", end=\"\")\n        print()\n        print()\n\nriemann_sum_analysis()\n\n# Properties of definite integrals\ndef integral_properties():\n    print(\"\\n=== INTEGRAL PROPERTIES ===\\n\")\n    \n    x = sp.Symbol('x')\n    \n    # Linearity: ∫(af(x) + bg(x)) dx = a∫f(x) dx + b∫g(x) dx\n    print(\"1. LINEARITY\")\n    a, b = 2, 3\n    f_expr = x**2\n    g_expr = sp.sin(x)\n    \n    # Left side: ∫(2x² + 3sin(x)) dx from 0 to 1\n    left_side = sp.integrate(a * f_expr + b * g_expr, (x, 0, 1))\n    \n    # Right side: 2∫x² dx + 3∫sin(x) dx from 0 to 1\n    right_side = a * sp.integrate(f_expr, (x, 0, 1)) + b * sp.integrate(g_expr, (x, 0, 1))\n    \n    print(f\"   ∫(2x² + 3sin(x)) dx = {left_side}\")\n    print(f\"   2∫x² dx + 3∫sin(x) dx = {right_side}\")\n    print(f\"   Linearity holds: {left_side == right_side}\")\n    \n    # Additivity: ∫ₐᵇ f(x) dx + ∫ᵇᶜ f(x) dx = ∫ₐᶜ f(x) dx\n    print(\"\\n2. ADDITIVITY\")\n    a, b, c = 0, 1, 2\n    \n    left_sum = sp.integrate(x**2, (x, a, b)) + sp.integrate(x**2, (x, b, c))\n    right_sum = sp.integrate(x**2, (x, a, c))\n    \n    print(f\"   ∫₀¹ x² dx + ∫₁² x² dx = {left_sum}\")\n    print(f\"   ∫₀² x² dx = {right_sum}\")\n    print(f\"   Additivity holds: {left_sum == right_sum}\")\n    \n    # Symmetry properties\n    print(\"\\n3. SYMMETRY PROPERTIES\")\n    \n    # Even function: ∫₋ₐᵃ f(x) dx = 2∫₀ᵃ f(x) dx\n    even_func = x**2\n    a_val = 2\n    \n    even_left = sp.integrate(even_func, (x, -a_val, a_val))\n    even_right = 2 * sp.integrate(even_func, (x, 0, a_val))\n    \n    print(f\"   ∫₋₂² x² dx = {even_left}\")\n    print(f\"   2∫₀² x² dx = {even_right}\")\n    print(f\"   Even function property holds: {even_left == even_right}\")\n    \n    # Odd function: ∫₋ₐᵃ f(x) dx = 0\n    odd_func = x**3\n    odd_result = sp.integrate(odd_func, (x, -a_val, a_val))\n    print(f\"   ∫₋₂² x³ dx = {odd_result}\")\n    print(f\"   Odd function property holds: {odd_result == 0}\")\n\nintegral_properties()\n\n### Applications in Machine Learning\n\nDefinite integrals are essential for:\n\n1. **Probability Calculations**: Computing probabilities from probability density functions\n2. **Expected Values**: Calculating means and moments of continuous distributions\n3. **Loss Function Analysis**: Understanding cumulative loss over intervals\n4. **Feature Importance**: Computing area-based feature contributions\n5. **Model Evaluation**: Area under ROC curves and precision-recall curves\n\n## 4.3 Integration Techniques\n\n### Substitution Method\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "python\n# Integration by substitution\ndef substitution_examples():\n    # ∫ x*e^(x²) dx using u = x²\n    # du = 2x dx, so dx = du/(2x)\n    # ∫ x*e^(x²) dx = ∫ x*e^u * du/(2x) = (1/2)∫ e^u du = (1/2)e^u + C = (1/2)e^(x²) + C\n    \n    # Using SymPy\n    integral = sp.integrate(x * sp.exp(x**2), x)\n    print(f\"∫ x*e^(x²) dx = {integral}\")\n    \n    # ∫ sin(2x) dx using u = 2x\n    integral2 = sp.integrate(sp.sin(2*x), x)\n    print(f\"∫ sin(2x) dx = {integral2}\")\n\nsubstitution_examples()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Integration by Parts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "python\n# Integration by parts: ∫ u dv = uv - ∫ v du\ndef integration_by_parts_examples():\n    # ∫ x*e^x dx\n    # Let u = x, dv = e^x dx\n    # Then du = dx, v = e^x\n    # ∫ x*e^x dx = x*e^x - ∫ e^x dx = x*e^x - e^x + C\n    \n    integral = sp.integrate(x * sp.exp(x), x)\n    print(f\"∫ x*e^x dx = {integral}\")\n    \n    # ∫ x*ln(x) dx\n    integral2 = sp.integrate(x * sp.log(x), x)\n    print(f\"∫ x*ln(x) dx = {integral2}\")\n\nintegration_by_parts_examples()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4.4 Applications in Probability and Statistics\n\n### Probability Density Functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "python\n# Normal distribution integration\ndef normal_distribution_integration():\n    # Standard normal distribution: f(x) = (1/√(2π)) * e^(-x²/2)\n    def normal_pdf(x):\n        return (1/np.sqrt(2*np.pi)) * np.exp(-x**2/2)\n    \n    # ∫₋∞^∞ f(x) dx = 1 (total probability)\n    total_prob, error = integrate.quad(normal_pdf, -np.inf, np.inf)\n    print(f\"Total probability: {total_prob:.6f}\")\n    \n    # P(-1 ≤ X ≤ 1) = ∫₋₁¹ f(x) dx\n    prob_1sigma, error = integrate.quad(normal_pdf, -1, 1)\n    print(f\"P(-1 ≤ X ≤ 1): {prob_1sigma:.6f}\")\n    \n    # P(-2 ≤ X ≤ 2) = ∫₋₂² f(x) dx\n    prob_2sigma, error = integrate.quad(normal_pdf, -2, 2)\n    print(f\"P(-2 ≤ X ≤ 2): {prob_2sigma:.6f}\")\n    \n    # Visualize\n    x_vals = np.linspace(-4, 4, 1000)\n    y_vals = normal_pdf(x_vals)\n    \n    plt.figure(figsize=(12, 5))\n    \n    # Full distribution\n    plt.subplot(1, 2, 1)\n    plt.plot(x_vals, y_vals, 'b-', linewidth=2)\n    plt.fill_between(x_vals, y_vals, alpha=0.3, color='blue')\n    plt.xlabel('x')\n    plt.ylabel('f(x)')\n    plt.title('Standard Normal Distribution')\n    plt.grid(True)\n    \n    # ±1σ region\n    plt.subplot(1, 2, 2)\n    plt.plot(x_vals, y_vals, 'b-', linewidth=2)\n    mask = (x_vals >= -1) & (x_vals <= 1)\n    plt.fill_between(x_vals[mask], y_vals[mask], alpha=0.5, color='red')\n    plt.xlabel('x')\n    plt.ylabel('f(x)')\n    plt.title('P(-1 ≤ X ≤ 1)')\n    plt.grid(True)\n    \n    plt.tight_layout()\n    plt.show()\n\nnormal_distribution_integration()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Expected Values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "python\n# Expected value calculations\ndef expected_value_examples():\n    # E[X] = ∫ x*f(x) dx for continuous random variables\n    \n    # Exponential distribution: f(x) = λ*e^(-λx) for x ≥ 0\n    def exponential_pdf(x, lambda_param=1):\n        return lambda_param * np.exp(-lambda_param * x)\n    \n    # E[X] = ∫₀^∞ x*λ*e^(-λx) dx = 1/λ\n    def expected_value_exponential(lambda_param=1):\n        integrand = lambda x: x * exponential_pdf(x, lambda_param)\n        result, error = integrate.quad(integrand, 0, np.inf)\n        return result\n    \n    expected_val = expected_value_exponential(1)\n    print(f\"E[X] for exponential(λ=1): {expected_val:.6f}\")\n    print(f\"Theoretical value: {1/1:.6f}\")\n    \n    # Variance: Var(X) = E[X²] - (E[X])²\n    def variance_exponential(lambda_param=1):\n        integrand = lambda x: x**2 * exponential_pdf(x, lambda_param)\n        e_x_squared, _ = integrate.quad(integrand, 0, np.inf)\n        e_x = expected_value_exponential(lambda_param)\n        return e_x_squared - e_x**2\n    \n    variance = variance_exponential(1)\n    print(f\"Var(X) for exponential(λ=1): {variance:.6f}\")\n    print(f\"Theoretical value: {1/1**2:.6f}\")\n\nexpected_value_examples()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4.5 Numerical Integration Methods\n\n### Trapezoidal Rule\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "python\n# Trapezoidal rule implementation\ndef trapezoidal_rule(f, a, b, n=1000):\n    \"\"\"Approximate ∫ₐᵇ f(x) dx using trapezoidal rule\"\"\"\n    x = np.linspace(a, b, n+1)\n    y = f(x)\n    h = (b - a) / n\n    return h * (0.5 * y[0] + np.sum(y[1:-1]) + 0.5 * y[-1])\n\n# Compare different methods\ndef compare_integration_methods():\n    f = lambda x: x**2\n    \n    # Exact value\n    exact = 1/3\n    \n    # Trapezoidal rule\n    trapezoidal = trapezoidal_rule(f, 0, 1, 100)\n    \n    # SciPy quad\n    scipy_result, _ = integrate.quad(f, 0, 1)\n    \n    print(f\"Exact value: {exact:.6f}\")\n    print(f\"Trapezoidal rule: {trapezoidal:.6f}\")\n    print(f\"SciPy quad: {scipy_result:.6f}\")\n    \n    # Error analysis\n    trapezoidal_error = abs(trapezoidal - exact)\n    scipy_error = abs(scipy_result - exact)\n    \n    print(f\"Trapezoidal error: {trapezoidal_error:.2e}\")\n    print(f\"SciPy error: {scipy_error:.2e}\")\n\ncompare_integration_methods()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Monte Carlo Integration\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "python\n# Monte Carlo integration\ndef monte_carlo_integration(f, a, b, n=10000):\n    \"\"\"Approximate ∫ₐᵇ f(x) dx using Monte Carlo method\"\"\"\n    x_random = np.random.uniform(a, b, n)\n    y_random = f(x_random)\n    return (b - a) * np.mean(y_random)\n\n# Example: ∫₀¹ x² dx\ndef monte_carlo_example():\n    f = lambda x: x**2\n    exact = 1/3\n    \n    # Run multiple times to see variation\n    results = []\n    for i in range(10):\n        result = monte_carlo_integration(f, 0, 1, 10000)\n        results.append(result)\n    \n    print(f\"Exact value: {exact:.6f}\")\n    print(f\"Monte Carlo results: {[f'{r:.6f}' for r in results]}\")\n    print(f\"Mean: {np.mean(results):.6f}\")\n    print(f\"Std: {np.std(results):.6f}\")\n\nmonte_carlo_example()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4.6 Applications in Machine Learning\n\n### Loss Function Integration\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "python\n# Integration in loss functions\ndef loss_function_integration():\n    # Expected loss over a distribution\n    def expected_loss(loss_func, data_distribution, n_samples=10000):\n        \"\"\"Calculate expected loss over a data distribution\"\"\"\n        samples = data_distribution.rvs(n_samples)\n        losses = [loss_func(x) for x in samples]\n        return np.mean(losses)\n    \n    # Example: Expected MSE loss\n    from scipy.stats import norm\n    \n    def mse_loss(x, target=0):\n        return (x - target)**2\n    \n    # Expected MSE when data follows N(0, 1)\n    expected_mse = expected_loss(mse_loss, norm(0, 1))\n    print(f\"Expected MSE for N(0,1): {expected_mse:.6f}\")\n    \n    # Theoretical: E[(X-0)²] = Var(X) = 1\n    print(f\"Theoretical value: {1:.6f}\")\n\nloss_function_integration()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Area Under ROC Curve (AUC)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "python\n# AUC calculation using integration\ndef calculate_auc():\n    # Simulate ROC curve data\n    np.random.seed(42)\n    n_samples = 1000\n    \n    # Generate scores for two classes\n    scores_class_0 = np.random.normal(0, 1, n_samples//2)\n    scores_class_1 = np.random.normal(1, 1, n_samples//2)\n    \n    # Calculate ROC curve\n    from sklearn.metrics import roc_curve, auc\n    \n    y_true = np.concatenate([np.zeros(n_samples//2), np.ones(n_samples//2)])\n    y_scores = np.concatenate([scores_class_0, scores_class_1])\n    \n    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n    auc_score = auc(fpr, tpr)\n    \n    print(f\"AUC: {auc_score:.6f}\")\n    \n    # Visualize ROC curve\n    plt.figure(figsize=(8, 6))\n    plt.plot(fpr, tpr, 'b-', linewidth=2, label=f'ROC curve (AUC = {auc_score:.3f})')\n    plt.plot([0, 1], [0, 1], 'k--', label='Random classifier')\n    plt.fill_between(fpr, tpr, alpha=0.3, color='blue')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\ncalculate_auc()\n```\n\n## Summary\n\n- **Antiderivatives** reverse the process of differentiation\n- **Definite integrals** calculate areas and cumulative effects\n- **Integration techniques** include substitution and integration by parts\n- **Numerical methods** provide approximations when symbolic integration is difficult\n- **Applications** include probability calculations, expected values, and performance metrics\n- **Machine learning** uses integration for AUC, expected losses, and probability distributions\n\n## Next Steps\n\nIntegration provides the foundation for understanding areas, volumes, and cumulative effects. In the next section, we'll explore applications of integration in optimization and advanced calculus concepts."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}